<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>SOHO论文阅读</title>
    <url>/2022/03/09/SOHO%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>上一篇ViLBERT模型提出了使用two-stream的结构来分别处理图片和文本信息，然后再进行融合，在“vision-and-language”任务上还有其他模型使用了这种双流结构，因为其架构比单流结构更为复杂，所以架构的种类更加丰富，为了更深入地了解这种处理不同层次信息（图片和文本）的架构方式，我阅读了Seeing Out of tHe bOx:End-to-End Pre-training for Vision-Language Representation Learning这篇论文。特别地，这篇论文提出的视觉特征的提取方法也有其独到之处，能够不受目标特征局限性的影响。</p>
<center>
<img src="/2022/03/09/SOHO%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/001.png" width="600px">
</center>
<span id="more"></span>
<p>论文地址和相关源码链接如下：</p>
<p><a href="https://arxiv.org/abs/2104.03135" target="_blank">论文地址：https://arxiv.org/abs/2104.03135</a> <br> <a href="https://github.com/researchmm/soho" target="_blank">相关源码：https://github.com/researchmm/soho</a></p>
<h3 id="摘要">摘要</h3>
<p>文章研究了用于视觉语言预训练的卷积神经网络和transformer的联合学习，旨在从数百万的图像-文本对中学习跨模态对齐，截止文章发表，最先进的方法是提取突出的图像区域并逐步将区域与文字对齐，但是由于提取出的图像区域仅仅代表图像的一部分，所以理解对应的自然语言是有难度的。文章提出了SOHO模型，将整个图像作为输入，并以端到端方式学习视觉语言的联合表示，SOHO模型不需要边界框标注，这使得其推理的速度比基于区域的方法块10倍。特别地，SOHO通过视觉字典(VD)学习提取全面而紧凑的图像特征，以促进跨模态的理解。最终，文章将SOHO模型在四个视觉语言任务上进行实验，并得到不错的性能和准确率提升。</p>
<h3 id="介绍">介绍</h3>
<p>最近跨模态学习的研究工作不断增加，特别是在视觉语言预训练(VLPT)领域。显而易见地，视觉表示在VLPT模型中起着重要作用，有一些模型利用了基于区域的图像特征并取得了不错的效果，这些特征是由在视觉基因组数据集上预训练的目标检测器提取出来的，但是这种方法也有一些缺点：</p>
<ol type="1">
<li>区域专注于边界框内的物体，而忽略了边界框外的上下文信息。这些信息对于区域与区域之间的关系理解和推理非常重要。文章以下图为例说明了这个事实，图中可以很容易地检测到男人、女人和船目标，但是如果缺少边框外的上下文信息，就会误以为人们在划船，从而导致模型在下游任务应用时的错误。</li>
</ol>
<center>
<img src="/2022/03/09/SOHO%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/002.png" width="500px">
<p style="font-family:KaiTi">
图1：模型在下游任务上的结果对比
</p>
</center>
<ol start="2" type="1">
<li>对图像的视觉理解被限制在预先定义的区域类别中。</li>
<li>大多数区域特征是由检测模型提取的，存在质量低、噪声大、过采样等问题，并且依赖于大规模的box标注数据。</li>
</ol>
<p>除了区域图像特征提取方法外，一些工作也研究了采用弱监督的目标检测的方法、或是通过基于网格的卷积特征来学习视觉表征的方法，但存在性能不高、只针对单个任务设计等问题。</p>
<p>为了克服基于区域的图像特征的局限性，更好地利用图像文本数据对进行跨模态理解，文章提出了一个端到端的视觉语言预训练框架SOHO，直接学习图像和文本的嵌入及其语义对齐。与现有的VLPT模型相比，SOHO采取了一个简单的管道，不需要复杂的视觉骨干进行预训练。相比于现有的基于区域的图像特征的方法，SOHO不需要标注类别或边界框，可以通过更广泛的图像-文本数据直接优化视觉表示来丰富视觉语义。</p>
<p>文章选择采用像素级的视觉表征，但像素级的视觉表征比语言的嵌入更加多样化和密集化，并且缺乏明确的监督，给对齐学习增加了难度。为了解决上述问题，文章引入了<strong>视觉字典</strong>，它代表了视觉领域中更全面和紧凑的语义。为了学习视觉字典，文中设计了一个移动平均编码器，将具有类似视觉语义的像素进行分组。</p>
<p>在预训练过程中，文章采用了Masked Vision Modeling (MVM) ，Masked Language Modeling（MLM），Image-Text Matching （ITM）三个任务来优化模型。</p>
<p>文章的贡献可以总结如下：</p>
<ol type="1">
<li>文章提出了SOHO模型，这是第一个直接用图像-文本对学习跨模态表示的端到端VLPT模型之一。在不需要提取边界框的情况下，模型可以实现至少10倍的推理速度。</li>
<li>为了更好地对齐图像和文本数据，我们提出了一个新的动态更新的视觉字典，它代表了图像中类似语义的视觉抽象。</li>
<li>对四个下游任务进行实验，得到了性能和准确率提升。</li>
</ol>
<h3 id="相关工作">相关工作</h3>
<h4 id="vision-language中的视觉表示">Vision-Language中的视觉表示</h4>
<p>早期的工作采用CNN分类模型来提取视觉特征，后来，Anderson等人提出了在视觉基因数据集上预训练的BUTD检测模型，以提取突出的区域特征作为视觉输入，最近，一些工作提出在特定的Vision-Language任务上，用卷积神经网络可以直接学习网格特征形式的视觉表征。</p>
<p>VideoBERT和bag of words文献也使用矢量量化来表示视觉信息。VD与相关作品的关键区别在于，我们用可训练的视觉编码器的输出动态更新基于VD的嵌入，而不是预先计算的输入特征（即VD是<strong>动态更新</strong>的）。VD的动态更新机制可以从视觉语言数据集中获取文本指导语义。因此，该模型可以直接用高级语义来优化视觉语言的理解和对齐。</p>
<h4 id="vision-language的预训练">Vision-Language的预训练</h4>
<p>许多视觉语言预训练工作已经被提出用来学习跨模态表征，它们可以被分为single-stream模型和two-stream模型，双流模型分别处理视觉和语言信息，并在之后通过另一个transformer层将它们融合；相反，单流模型使用BERT来学习检测边界框特征（可以理解为ROI特征）和文本嵌入特征的双向联合分布。这两种类型都使用基于Transformer的模型来学习视觉-语言联合嵌入特征。虽然他们忽略了视觉表征学习对视觉-语言任务也很重要。</p>
<h3 id="方法">方法</h3>
<p>SOHO是一个端到端的框架，它由一个基于CNN的可训练的视觉编码器、一个视觉字典嵌入模块和一个多层transformer组成，视觉编码器将图像作为输入并产生视觉特征，视觉字典嵌入模块被设计用来将不同的视觉语义信息聚集到视觉token中，transformer被用来融合视觉和语言模态的特征，并产生特定任务的输出。SOHO可以通过MVM、MLM和ITM任务进行端到端的预训练，并很容易地适应下游任务。SOHO的整体架构如下图所示，</p>
<center>
<img src="/2022/03/09/SOHO%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/003.png" width="700px">
<p style="font-family:KaiTi">
图2：SOHO模型架构
</p>
</center>
<h4 id="可训练的视觉编码器">可训练的视觉编码器</h4>
<p>基于区域的图像特征的表现能力受到预先定义的对象和属性类别的限制，并且不能学习到某些边界框外的上下文信息。为了保留所有视觉信息，文章建议使用一个可训练的CNN视觉编码器，将整个图像作为输入，产生图像级别的视觉特征，而不是区域级别的特征。由于不受边界框的限制，视觉编码器可以从预训练的损失函数或下游任务的损失函数中进行端到端的更新，进而进一步优化跨模态学习。给定一张图片<span class="math inline">\(\mathcal{I}\)</span>，可以根据以下公式得到其特征<span class="math inline">\(\mathcal{V}\)</span>，</p>
<p><span class="math display">\[
\mathcal{V}=E(\mathcal{I}, \theta) \in \mathbf{R}^{l \times c}
\]</span></p>
<p>其中<span class="math inline">\(l\)</span>表示嵌入特征向量的数量，<span class="math inline">\(c\)</span>表示嵌入特征向量维度，另外，将在ImageNet上预训练的ResNet加上<span class="math inline">\(1 \times 1\)</span>的卷积层和<span class="math inline">\(2 \times 2\)</span>最大池化层作为编码器<span class="math inline">\(E\)</span>的结构。</p>
<h4 id="视觉字典">视觉字典</h4>
<p>视觉特征编码器提取的视觉特征<span class="math inline">\(\mathcal{V}\)</span>比语言词标记更加多样和密集，这将给跨模态理解的学习带来困难。为了弥补其与语言token的差距，我们提出了一个视觉字典，通过将相似的视觉语义聚合到同一图像特征中来标记视觉特征。</p>
<h5 id="视觉字典嵌入">视觉字典嵌入</h5>
<p>文章将视觉字典定义为一个矩阵<span class="math inline">\(\mathcal{D} \in \mathbf{R}^{k \times c}\)</span>，包含<span class="math inline">\(k\)</span>个嵌入向量，每个<span class="math inline">\(c\)</span>维，第<span class="math inline">\(j\)</span>个嵌入向量被表示为<span class="math inline">\(d_{j}\)</span>，对于每一个视觉特征<span class="math inline">\(v_{i}\)</span>，文章通过在<span class="math inline">\(\mathcal{D}\)</span>中搜索最近邻来计算其映射索引<span class="math inline">\(h_{i}\)</span>，记为如下公式，</p>
<p><span class="math display">\[
h_{i}=\operatorname{argmin}_{j}\left\|v_{i}-d_{j}\right\|_{2}
\]</span></p>
<p>因此可以定义以下映射函数<span class="math inline">\(f\)</span>，将视觉特征<span class="math inline">\(v_{i}\)</span>映射到视觉字典矩阵<span class="math inline">\(\mathcal{D}\)</span>：</p>
<p><span class="math display">\[
f\left(v_{i}\right)=d_{h_{i}}
\]</span></p>
<p>其使用视觉字典中最近的嵌入向量来表示视觉特征，<span class="math inline">\(f^{-1}(j)\)</span>表示逆映射函数，将索引<span class="math inline">\(j\)</span>映射回一组视觉特征。</p>
<h5 id="视觉字典的学习更新">视觉字典的学习更新</h5>
<p>视觉字典矩阵被随机初始化，并在一个小批次中通过移动平均操作进一步更新，记为如下公式，</p>
<p><span class="math display">\[
\hat{d}_{j}=\gamma * d_{j}+(1-\gamma) * \frac{\sum_{h_{i}=j} v_{i}}{\left|f^{-1}(j)\right|}
\]</span></p>
<p>即保留一部分原有的<span class="math inline">\(d_{j}\)</span>，根据小批次中被归为<span class="math inline">\(h_{j}\)</span>索引的视觉特征进行更新。</p>
<h5 id="梯度反向传播">梯度反向传播</h5>
<p>由于argmin操作时不可微的，梯度反向传播将被视觉字典停止，为了使视觉编码器可训练，采用了以下方法进行更新，</p>
<p><span class="math display">\[
f\left(v_{i}\right)=s g\left[d_{h_{i}}-v_{i}\right]+v_{i}
\]</span></p>
<p>其中<span class="math inline">\(s g[\cdot]\)</span>为停止梯度运算符。</p>
<p>视觉词典根据特征相似度对视觉特征图进行在线聚类，并通过聚类中心表示每个特征向量。具有相似语义的特征向量将被聚集到同一个聚类中，聚类的索引可以被视为一个虚拟的视觉语义标签。<strong>由于聚类可以受到视觉语言学习任务的影响，每个嵌入向量的学习语义更适合于跨模态的理解和对齐。</strong></p>
<p>视觉字典面临着一个冷启动问题，直接将梯度从随机初始化的嵌入向量复制到视觉特征图上会导致不正确的模型优化方向（即模式崩溃）。因此，我们在前10个训练历时中冻结了视觉特征编码器中ResNet的参数。</p>
<h4 id="预训练管道">预训练管道</h4>
<p>文章应用多层transformer来学习融合视觉和语言特征的跨模态表征，为了学习视觉和语言相关任务的通用表征，文章采用自监督的方法，在一个大型的数据集上对模型进行预训练。除了通用的掩蔽语言建模和图像-文本匹配预训练任务外，文章还提出了一个新颖的基于视觉字典产生的虚拟视觉语义标签的掩蔽视觉建模预训练任务。</p>
<h5 id="跨模态的transformer">跨模态的transformer</h5>
<p>对于视觉表示，文章利用正弦函数计算的二维位置嵌入来编码视觉token的空间信息，对于文本内容，按照输入BERT时的嵌入方法对其进行文本进行嵌入，最终将VD嵌入和文本嵌入连接起来形成输入序列，用于跨模态学习，需要特别注意的是，VD嵌入与文本嵌入的向量长度一致。</p>
<h5 id="掩蔽语言建模mlm">掩蔽语言建模(MLM)</h5>
<p>掩蔽语言建模预训练任务鼓励模型构建语言token和可视化内容之间的映射关系，MLM的目标是根据其他词token<span class="math inline">\(\mathcal{W}_{\backslash i}\)</span>和所有的图像特征<span class="math inline">\(f(\mathcal{V})\)</span>，通过最小化负对数似然来预测遮蔽的词token：</p>
<p><span class="math display">\[
\mathcal{L}_{\mathrm{MLM}}=-\mathbb{E}_{(\mathcal{W}, f(\mathcal{V})) \sim D} \log p\left(w_{i} \mid \mathcal{W}_{\backslash i}, f(\mathcal{V})\right)
\]</span></p>
<h5 id="掩蔽视觉建模mvm">掩蔽视觉建模(MVM)</h5>
<p>文章提出了基于视觉字典的掩蔽视觉建模，在将图像特征输入到transformer之前，随机进行遮蔽，MVM的目标是根据周围图像的特征<span class="math inline">\(f(\mathcal{V})_{\backslash j}\)</span>和所有的语言token<span class="math inline">\(W\)</span>，通过最小化负对数似然，预测被遮蔽图像的特征，</p>
<p><span class="math display">\[
\mathcal{L}_{\text {MVM }}=-\mathbb{E}_{(\mathcal{W}, f(\mathcal{V})) \sim D} \log p\left(f\left(v_{j}\right) \mid \mathcal{W}, f(\mathcal{V})_{\backslash j}\right)
\]</span></p>
<p>需要特别注意的是，在视觉特征图中，相邻的特征可能有相似的值，因此共享相同的视觉字典映射索引，这将导致模型以一种懒惰的方式直接复制周围特征的标签作为预测值，为了防止这种情况的出现，在遮蔽阶段，文章首先在视觉字典中随机选择一个标签索引，然后将索引对应的所有视觉特征进行遮蔽。</p>
<h5 id="图像-文本匹配itm">图像-文本匹配(ITM)</h5>
<p>为了增强跨模态匹配，文章采用图像文本匹配任务进行预训练，文章在[CLS]标签上应用二值分类器<span class="math inline">\(\phi(\cdot)\)</span>来预测输入图像和文本是否匹配，ITM任务由以下的损失函数驱动：</p>
<p><span class="math display">\[
\mathcal{L}_{\mathrm{ITM}}=-\mathbb{E}_{(\mathcal{W}, f(\mathcal{V})) \sim D} \log p(y \mid \phi(\mathcal{W}, f(\mathcal{V})))
\]</span></p>
<p>视觉特征编码器、基于VD的图像嵌入模块和跨模态transformer可以进行端到端的联合训练，文章给三个预训练目标分配相同的损失权重，因此，SOHO的预训练目标如下所示，</p>
<p><span class="math display">\[
\mathcal{L}_{\text {Pre-training }}=\mathcal{L}_{\mathrm{MLM}}+\mathcal{L}_{\mathrm{MVM}}+\mathcal{L}_{\mathrm{ITM}}
\]</span></p>
]]></content>
      <categories>
        <category>深度学习论文阅读</category>
      </categories>
      <tags>
        <tag>多模态模型</tag>
      </tags>
  </entry>
  <entry>
    <title>LibRec学习笔记（一）：BiasedMF算法</title>
    <url>/2022/04/04/LibRec%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9ABiasedMF%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近推荐系统导论课程需要使用LibRec库实现一些推荐算法，其实LibRec库已经封装了很多算法，并不需要再去实现，只需要调用命令行修改配置就可以运行，但为了更好地理解算法，我阅读了LibRec库的一些算法的源码，以下是BiaseMF算法在LibRec库中的实现，本文主要从三部分展开讲解，分别是预测公式、损失函数公式和更新公式。 <span id="more"></span></p>
<h1 id="代码展示">代码展示</h1>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// SVDPlusPlusRecommender类继承BiasedMFRecommender父类</span></span><br><span class="line"><span class="keyword">package</span> net.librec.recommender.cf.rating;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> net.librec.annotation.ModelData;</span><br><span class="line"><span class="keyword">import</span> net.librec.common.LibrecException;</span><br><span class="line"><span class="keyword">import</span> net.librec.math.structure.MatrixEntry;</span><br><span class="line"><span class="keyword">import</span> net.librec.math.structure.VectorBasedDenseVector;</span><br><span class="line"><span class="keyword">import</span> net.librec.recommender.MatrixFactorizationRecommender;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ModelData(&#123;&quot;isRating&quot;, &quot;biasedMF&quot;, &quot;userFactors&quot;, &quot;itemFactors&quot;, &quot;userBiases&quot;, &quot;itemBiases&quot;&#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BiasedMFRecommender</span> <span class="keyword">extends</span> <span class="title">MatrixFactorizationRecommender</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">double</span> regBias;</span><br><span class="line">    <span class="keyword">protected</span> VectorBasedDenseVector userBiases;</span><br><span class="line">    <span class="keyword">protected</span> VectorBasedDenseVector itemBiases;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">BiasedMFRecommender</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">()</span> <span class="keyword">throws</span> LibrecException </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.setup();</span><br><span class="line">        <span class="keyword">this</span>.regBias = <span class="keyword">this</span>.conf.getDouble(<span class="string">&quot;rec.bias.regularization&quot;</span>, <span class="number">0.01D</span>);</span><br><span class="line">        <span class="comment">// 用户偏差向量</span></span><br><span class="line">        <span class="keyword">this</span>.userBiases = <span class="keyword">new</span> VectorBasedDenseVector(<span class="keyword">this</span>.numUsers);</span><br><span class="line">        <span class="comment">// 物品偏差向量</span></span><br><span class="line">        <span class="keyword">this</span>.itemBiases = <span class="keyword">new</span> VectorBasedDenseVector(<span class="keyword">this</span>.numItems);</span><br><span class="line">        <span class="comment">// 用户偏差初始化</span></span><br><span class="line">        <span class="keyword">this</span>.userBiases.init((<span class="keyword">double</span>)<span class="keyword">this</span>.initMean, (<span class="keyword">double</span>)<span class="keyword">this</span>.initStd);</span><br><span class="line">        <span class="comment">// 物品偏差初始化</span></span><br><span class="line">        <span class="keyword">this</span>.itemBiases.init((<span class="keyword">double</span>)<span class="keyword">this</span>.initMean, (<span class="keyword">double</span>)<span class="keyword">this</span>.initStd);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">trainModel</span><span class="params">()</span> <span class="keyword">throws</span> LibrecException </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> iter = <span class="number">1</span>; iter &lt;= <span class="keyword">this</span>.numIterations; ++iter) &#123;</span><br><span class="line">            <span class="comment">// 损失</span></span><br><span class="line">            <span class="keyword">this</span>.loss = <span class="number">0.0D</span>;</span><br><span class="line"></span><br><span class="line">            Iterator var2 = <span class="keyword">this</span>.trainMatrix.iterator();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span>(var2.hasNext()) &#123;</span><br><span class="line">                MatrixEntry matrixEntry = (MatrixEntry)var2.next();</span><br><span class="line">                <span class="keyword">int</span> userIdx = matrixEntry.row();</span><br><span class="line">                <span class="keyword">int</span> itemIdx = matrixEntry.column();</span><br><span class="line">                <span class="comment">// 实际评分</span></span><br><span class="line">                <span class="keyword">double</span> realRating = matrixEntry.get();</span><br><span class="line">                <span class="comment">// 预测评分</span></span><br><span class="line">                <span class="keyword">double</span> predictRating = <span class="keyword">this</span>.predict(userIdx, itemIdx);</span><br><span class="line">                <span class="comment">// 实际评分与预测评分的误差</span></span><br><span class="line">                <span class="keyword">double</span> error = realRating - predictRating;</span><br><span class="line">                <span class="keyword">this</span>.loss += error * error;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 根据当前用户ID得到当前用户偏差向量</span></span><br><span class="line">                <span class="keyword">double</span> userBiasValue = <span class="keyword">this</span>.userBiases.get(userIdx);</span><br><span class="line">                <span class="comment">// 用户偏置项的更新公式</span></span><br><span class="line">                <span class="keyword">this</span>.userBiases.plus(userIdx, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error - <span class="keyword">this</span>.regBias * userBiasValue));</span><br><span class="line"></span><br><span class="line">                <span class="keyword">this</span>.loss += <span class="keyword">this</span>.regBias * userBiasValue * userBiasValue;</span><br><span class="line">                <span class="comment">// 根据当前物品ID得到当前物品偏差向量</span></span><br><span class="line">                <span class="keyword">double</span> itemBiasValue = <span class="keyword">this</span>.itemBiases.get(itemIdx);</span><br><span class="line">                <span class="comment">// 物品偏置项的更新公式</span></span><br><span class="line">                <span class="keyword">this</span>.itemBiases.plus(itemIdx, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error - <span class="keyword">this</span>.regBias * itemBiasValue));</span><br><span class="line"></span><br><span class="line">                <span class="keyword">this</span>.loss += <span class="keyword">this</span>.regBias * itemBiasValue * itemBiasValue;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> factorIdx = <span class="number">0</span>; factorIdx &lt; <span class="keyword">this</span>.numFactors; ++factorIdx) &#123;</span><br><span class="line">                    <span class="keyword">double</span> userFactorValue = <span class="keyword">this</span>.userFactors.get(userIdx, factorIdx);</span><br><span class="line">                    <span class="keyword">double</span> itemFactorValue = <span class="keyword">this</span>.itemFactors.get(itemIdx, factorIdx);</span><br><span class="line">                    <span class="keyword">this</span>.userFactors.plus(userIdx, factorIdx, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error * itemFactorValue - (<span class="keyword">double</span>)<span class="keyword">this</span>.regUser * userFactorValue));</span><br><span class="line">                    <span class="keyword">this</span>.itemFactors.plus(itemIdx, factorIdx, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error * userFactorValue - (<span class="keyword">double</span>)<span class="keyword">this</span>.regItem * itemFactorValue));</span><br><span class="line">                    <span class="keyword">this</span>.loss += (<span class="keyword">double</span>)<span class="keyword">this</span>.regUser * userFactorValue * userFactorValue + (<span class="keyword">double</span>)<span class="keyword">this</span>.regItem * itemFactorValue * itemFactorValue;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">this</span>.loss *= <span class="number">0.5D</span>;</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.isConverged(iter) &amp;&amp; <span class="keyword">this</span>.earlyStop) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">this</span>.updateLRate(iter);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">double</span> <span class="title">predict</span><span class="params">(<span class="keyword">int</span> userIdx, <span class="keyword">int</span> itemIdx)</span> <span class="keyword">throws</span> LibrecException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.userFactors.row(userIdx).dot(<span class="keyword">this</span>.itemFactors.row(itemIdx)) + <span class="keyword">this</span>.userBiases.get(userIdx) + <span class="keyword">this</span>.itemBiases.get(itemIdx) + <span class="keyword">this</span>.globalMean;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="预测公式">预测公式</h1>
<p><span class="math inline">\(\hat{r_{u i}}=\mu+b_{i}+b_{u}+p_{u} q_{i}^{T}\)</span></p>
<p>其中，<span class="math inline">\(\mu\)</span>表示全局均值，在代码中使用<code>this.globalMean</code>表示，<span class="math inline">\(b_{i}\)</span>表示物品偏差项，在代码中使用<code>this.itemBiases.get(itemIdx)</code>表示，需要注意的是，物品偏置项需要根据物品ID进行索引，<span class="math inline">\(b_{u}\)</span>表示用户偏差项，在代码中使用<code>this.userBiases.get(userIdx)</code>表示，同样地，用户偏置项需要根据用户ID来进行索引，<span class="math inline">\(p_{u}\)</span>表示对用户评分矩阵进行矩阵分解后得到的用户向量，<span class="math inline">\(q_{i}\)</span>表示对用户评分矩阵进行分解后得到的物品向量。</p>
<ul>
<li>PS：这里说是用户向量和物品向量的原因是都是针对某一用户和物品进行计算。</li>
</ul>
<p>预测公式代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">double</span> <span class="title">predict</span><span class="params">(<span class="keyword">int</span> userIdx, <span class="keyword">int</span> itemIdx)</span> <span class="keyword">throws</span> LibrecException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.userFactors.row(userIdx).dot(<span class="keyword">this</span>.itemFactors.row(itemIdx)) + <span class="keyword">this</span>.userBiases.get(userIdx) + <span class="keyword">this</span>.itemBiases.get(itemIdx) + <span class="keyword">this</span>.globalMean;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>传入<code>userIdx</code>和<code>itemIdx</code>的原因是需要明确特定用户和特定物品，才能进行预测评分，<code>userFactors</code>和<code>itemFactors</code>是对用户评分矩阵进行矩阵分解后得到的用户矩阵和物品矩阵，需要明确索引才能使用。</p>
<h1 id="损失函数公式">损失函数公式</h1>
<p><span class="math inline">\(\sum_{r_{u i} \in R_{\text {train }}}\left(r_{u i}-\hat{r}_{u i}\right)^{2}+\lambda\left(b_{i}^{2}+b_{u}^{2}+\left\|q_{i}\right\|^{2}+\left\|p_{u}\right\|^{2}\right)\)</span></p>
<p>将用户对物品的特定评分与真实评分之间的差值的平方作为损失函数的一部分是显而易见的，在代码中体现如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 实际评分</span></span><br><span class="line"><span class="keyword">double</span> realRating = matrixEntry.get();</span><br><span class="line"><span class="comment">// 预测评分</span></span><br><span class="line"><span class="keyword">double</span> predictRating = <span class="keyword">this</span>.predict(userIdx, itemIdx);</span><br><span class="line"><span class="comment">// 实际评分与预测评分的误差</span></span><br><span class="line"><span class="keyword">double</span> error = realRating - predictRating;</span><br><span class="line"><span class="keyword">this</span>.loss += error * error;</span><br></pre></td></tr></table></figure>
<p>通过以上展示的<code>predict()</code>函数可以直接根据用户ID与物品ID求出预测评分，但值得琢磨的是，实际评分是如何得到的？</p>
<p>可以看到，<code>MatrixEntry</code>接口是如下定义的，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">MatrixEntry</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">row</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">column</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">get</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">set</span><span class="params">(<span class="keyword">double</span> var1)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">rowPosition</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">columnPosition</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>SequentialSparseMatrixEntry</code>类中实现了<code>MatrixEntry</code>接口的<code>get()</code>方法，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.tempVector.getAtPosition(<span class="keyword">this</span>.columnPosition);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>值得注意的是，在<code>SequentialSparseMatrixEntry</code>类中，<code>columnPosition</code>属性被初始化为<code>-1</code>，这就让我们联想到，标签的值总是被设置在最后一列，我们可以验证这个猜想，在代码中，<code>var2</code>被强制转换为<code>MatrixEntry</code>类型，而<code>var2</code>又是<code>trainMatrix</code>的一个迭代器，不出所料地，<code>trainMatrix</code>是·<code>SequentialAccessSparseMatrix</code>类型，所以程序中可以直接调用<code>get()</code>方法来获取数据集中的实际评分值。</p>
<p>我们重新来回到损失函数的话题上，接下来需要关注正则项的那一部分，即</p>
<p><span class="math inline">\(\lambda\left(b_{i}^{2}+b_{u}^{2}+\left|q_{i}\right|^{2}+\left|p_{u}\right|^{2}\right)\)</span></p>
<p>首先我们关注<span class="math inline">\(\lambda(b_{i}^{2}+b_{u}^{2})\)</span>，这一部分的代码比较好写，根据索引找到特定的用户偏置向量和物品偏置向量就可以写出代码，代码如下所示，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> userBiasValue = <span class="keyword">this</span>.userBiases.get(userIdx);</span><br><span class="line"><span class="keyword">this</span>.loss += <span class="keyword">this</span>.regBias * userBiasValue * userBiasValue;</span><br><span class="line"><span class="keyword">double</span> itemBiasValue = <span class="keyword">this</span>.itemBiases.get(itemIdx);</span><br><span class="line"><span class="keyword">this</span>.loss += <span class="keyword">this</span>.regBias * itemBiasValue * itemBiasValue;</span><br></pre></td></tr></table></figure>
<p>接下来的一部分就可能比较难懂，在对用户评分矩阵进行分解时，我们有一个超参数<span class="math inline">\(K\)</span>，表示的是隐因子的个数，在电影的用户评分矩阵中，隐因子指的可能是喜剧片、动画片等内容，换言之，用户是因为这些隐因子才作出的这些评分，所以矩阵分解的公式可以表示如下，</p>
<p><span class="math inline">\(\hat{r_{u i}}=p_{u} q_{i}^{T}=\sum_{k=1}^{K} p_{u k} q_{k i}^{T}=\sum_{k=1}^{K} p_{u k} q_{i k} \approx r_{u i}\)</span></p>
<p>所以在代码中我们需要增加一层遍历，即从1到<span class="math inline">\(K\)</span>对隐因子的遍历，对应每一种隐因子ID和用户ID有不同的用户隐因子值，同样的，对于每一种隐因子ID和物品ID有不同的物品隐因子值，对于<span class="math inline">\(\lambda\left(\left|q_{ik}\right|^{2}+\left|p_{uk}\right|^{2}\right)\)</span>这一部分的代码如下所示，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> factorIdx = <span class="number">0</span>; factorIdx &lt; <span class="keyword">this</span>.numFactors; ++factorIdx) &#123;</span><br><span class="line">    <span class="keyword">double</span> userFactorValue = <span class="keyword">this</span>.userFactors.get(userIdx, factorIdx);</span><br><span class="line">    <span class="keyword">double</span> itemFactorValue = <span class="keyword">this</span>.itemFactors.get(itemIdx, factorIdx);</span><br><span class="line">    <span class="keyword">this</span>.loss += (<span class="keyword">double</span>)<span class="keyword">this</span>.regUser * userFactorValue * userFactorValue + (<span class="keyword">double</span>)<span class="keyword">this</span>.regItem * itemFactorValue * itemFactorValue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上就是损失函数全部的内容。</p>
<h1 id="更新公式">更新公式</h1>
<p><span class="math inline">\(\begin{array}{l} b_{u} \leftarrow b_{u}+\gamma\left(e_{u i}-\lambda b_{u}\right) \\ b_{i} \leftarrow b_{i}+\gamma\left(e_{u i}-\lambda b_{i}\right) \\ p_{u} \leftarrow p_{u}+\gamma\left(e_{u i} \cdot q_{i}-\lambda p_{u}\right) \\ q_{i} \leftarrow q_{i}+\gamma\left(e_{u i} \cdot p_{u}-\lambda q_{i}\right) \end{array}\)</span></p>
<p>有了预测函数和损失函数的铺垫，这一部分就可以直接上代码，函数变量基本是差不多的，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">this</span>.userBiases.plus(userIdx, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error - <span class="keyword">this</span>.regBias * userBiasValue));</span><br><span class="line"><span class="keyword">this</span>.itemBiases.plus(itemIdx, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error - <span class="keyword">this</span>.regBias * itemBiasValu));</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> factorIdx = <span class="number">0</span>; factorIdx &lt; <span class="keyword">this</span>.numFactors; ++factorIdx) &#123;</span><br><span class="line">    <span class="keyword">double</span> userFactorValue = <span class="keyword">this</span>.userFactors.get(userIdx, factorIdx);</span><br><span class="line">    <span class="keyword">double</span> itemFactorValue = <span class="keyword">this</span>.itemFactors.get(itemIdx, factorIdx);</span><br><span class="line">    <span class="keyword">this</span>.userFactors.plus(userIdx, factorIdx, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error * itemFactorValue - (<span class="keyword">double</span>)<span class="keyword">this</span>.regUser * userFactorValue));</span><br><span class="line">    <span class="keyword">this</span>.itemFactors.plus(itemIdx, factorIdx, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error * userFactorValue - (<span class="keyword">double</span>)<span class="keyword">this</span>.regItem * itemFactorValue));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>只需要注意一点，<code>plus()</code>函数是需要知道具体索引位置才能进行更新的，所以需要传入索引参数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// DenseVector类中的plus方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">plus</span><span class="params">(<span class="keyword">int</span> index, <span class="keyword">double</span> value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.set(index, value + <span class="keyword">this</span>.get(index));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// DenseMatrix类中的plus方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">plus</span><span class="params">(<span class="keyword">int</span> row, <span class="keyword">int</span> column, <span class="keyword">double</span> value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span>[] var10000 = <span class="keyword">this</span>.values[row];</span><br><span class="line">    var10000[column] += value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/09/06/hello-world/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <tags>
        <tag>hello world</tag>
      </tags>
  </entry>
  <entry>
    <title>ViLBERT论文阅读</title>
    <url>/2022/03/08/ViLBERT%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>BERT模型的提出使得大规模的预训练成为可能，与BERT模型仅仅处理文本模态不同，ViLBERT模型结合了图片和文本信息的特征，使用two-stream结构，基于大型的图像标题数据库训练与下游任务无关的通用模型，基于该模型通过少量调整即可实现通过标题检索图片、视觉问答等具体任务，最近在学习多模态特征有效的融合和对齐方法，于是对这篇文章进行了研读。</p>
<center>
<img src="/2022/03/08/ViLBERT%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/001.png" width="600px">
</center>
<span id="more"></span>
<p>论文地址和相关源码链接如下，</p>
<p><a href="https://arxiv.org/pdf/1908.02265.pdf" target="_blank">论文地址：https://arxiv.org/pdf/1908.02265.pdf</a> <br> <a href="https://github.com/facebookresearch/vilbert-multi-task" target="_blank">相关源码：https://github.com/facebookresearch/vilbert-multi-task</a></p>
<h3 id="摘要">摘要</h3>
<p>ViLBERT模型是一个学习与任务无关的图像文本特征联合表示的模型，文章将流行的针对文本模态的BERT架构扩展到一个多模态的two-stream模型架构，在不同的流中处理视觉和文本输入，并通过共同注意的transformer层进行信息交互。文章通过自动收集的大型概念性标题数据集上定义两个代理任务，来对模型进行预训练，然后将其转移到多个既定的下游视觉和语言任务中，包括视觉问题回答、视觉常识推理、指代表达和基于标题的图像检索任务，在进行下游任务时只对基础架构做少量的补充。文章观察到，与现有的特定任务模型相比，在所有的四个下游任务上都实现了最先进的改进。文章认为，其工作代表了一种转变，即不再把学习视觉和语言之间的grounding作为任务训练的一部分，而是将visual grounding作为一种可预训练和可转移的能力。</p>
<blockquote>
<p>PS: visual grounding涉及视觉和文本两个模态，输入是图片和对应的物体描述，输出是描述物体的box，与目标检测不同的是，输入多了语言信息，在对物体进行定位时，要先对语言模态的输入进行理解，并且和视觉模态的信息进行融合，最后利用得到的特征进行定位预测。</p>
</blockquote>
<h3 id="介绍">介绍</h3>
<p>近年来，通过图像、视频等生成文本的研究已有了很多丰硕的成果，这些方法和任务可归结为“vision-and-language”。虽然这些任务都需要将自然语言和视觉特征结合，但是“vision-and-language”任务还没有一个统一的基础来提升这种结合能力。“vision-and-language”现在通常的做法是先分别预训练语言和视觉模型，然后通过任务进行基础知识的学习。通过这种方法学到的基础知识并不可靠，如果数据量不足或者是有bias的，那么模型的泛化能力会很差。</p>
<p>首先对模型进行预训练，然后再在目标任务上进行微调的手段已经被广泛使用，ViLBERT也采用了这种先预训练后转移的方案，并在预训练时尽可能地学习视觉和文本之间的关系。</p>
<p>为了学习这些联合的视觉-语言表征，我们借鉴了自监督学习方面的成功经验，这些成功通过训练模型来执行代理任务，从大量的无标签数据源中获取丰富的语义和结构信息，这些代理任务包括预测掩蔽词等等。为了通过类似的方法学习visual grounding，必须确定一个视觉和语言能够对齐的数据源来学习模态之间的关系，文章采用了概念性标题数据集。</p>
<p>文章提出了一个联合模型ViLBERT，用于从成对的视觉语言数据中学习与目标任务无关的visual grounding。文章的方法扩展了最近的BERT语言模型来共同推理文本和图像，关键技术创新是为视觉和语言处理引入单独的流，通过共同注意的transformer层进行信息交互，这种结构可以适应每种模态的不同处理需求，并在不同深度的模态之间提供互动，文章在实验中证明，two-stream结构优于single-stream结构。模型结构如下图所示，</p>
<center>
<img src="/2022/03/08/ViLBERT%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/002.png" width="700px">
<p style="font-family:KaiTi">
图1：ViLBERT模型结构
</p>
</center>
<p>文章使用两种代理任务来训练模型：</p>
<ol type="1">
<li>遮蔽部分图片区域和文本单词，根据上下文内容预测被遮蔽部分。</li>
<li>预测文字和图片是否匹配。</li>
</ol>
<p>将预训练模型作为基础，用于四个目标视觉语言任务，分别是视觉问题回答、视觉常识推理、指代表达和基于标题的图像检索。</p>
<h3 id="方法">方法</h3>
<h4 id="bert">BERT</h4>
<p>BERT模型时一个基于注意力机制的双向语言模型，当在大型语言语料库上进行预训练时，BERT已被证明对多种自然语言处理任务的迁移学习非常有效。</p>
<p>ViLBERT修改了BERT的键值注意机制，开发了一个多模态的共同注意transformer模块，通过在多头注意中交换键值对，这种结构使视觉注意到的文本特征被纳入到视觉表征中，同时将文本注意大的视觉特征纳入到文本表征中，BERT结构的标准transformer模块和ViLBERT结构的共同注意transformer模块对比图如下所示，</p>
<center>
<img src="/2022/03/08/ViLBERT%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/003.png" width="600px">
<p style="font-family:KaiTi">
图2：标准transformer模块和共同注意transformer模块对比
</p>
</center>
<p>下面简单地介绍BERT的输入文本表示和预训练任务。BERT的输入文本表示由三部分构成，分别是位置嵌入(position embedding)、段嵌入(segment embedding)和目标词嵌入(token embedding)。BERT的预训练任务包括掩蔽语言建模和下一句预测。具体的对于BERT模型的介绍可以参考原论文，传送门如下，</p>
<p><a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank">传送门：https://arxiv.org/pdf/1810.04805.pdf</a></p>
<h4 id="vilbert扩展bert以联合表示图像和文本">ViLBERT：扩展BERT以联合表示图像和文本</h4>
<p>受BERT模型在语言建模方面的成功启发，我们希望开发类似的模型和训练任务，从成对的数据中学习语言和视觉内容的联合表示，具体来说，文章考虑联合表示静态图像和相应的描述性文本。</p>
<p>文章首先叙述了一些直观的想法。可以首先将视觉输入的空间离散化，将这些视觉标记完全视为文本输入，并输入到预训练的BERT模型中，这种方法为single-stream方法。文章说明了single-stream方法的一些缺点：</p>
<ol type="1">
<li>最初的聚类可能会导致离散化错误，并失去重要的视觉细节。</li>
<li>以上方法对两种模态的输入进行了相同的处理，忽略了它们可能由于其固有的复杂性或其输入表征的初始抽象水平而需要不同的处理水平。</li>
<li>强迫预训练的权重去适应大量额外的视觉标记，可能会损害学到的BERT语言模型。</li>
</ol>
<p>基于以上缺点，文章开发了一个two-stream架构，分别对每个模态进行建模，然后通过基于注意力的互动来融合它们，这种方法允许每个模态的网络深度不同，并能在不同的深度上实现跨模态连接。</p>
<p>如图1所示，ViLBERT学习的是静态图像及其对应描述文本的联合表征，分别对两种模态进行建模，然后通过一组基于注意力机制的信息交互将它们融合在一起。对每种模态都可使用不同深度的网络，并支持不同深度的跨模态交互。双流架构中的每个流都是由一系列的TRM(transformer block)和Co-TRM组成，可以观察到，流之间的信息交互被限制在特定层，文本特征需要先经过TRM模块处理才能进行信息交互，文章给出的解释是所选择的视觉特征已经相对高级，与句子中的单词相比，视觉特征需要有限的上下文聚合。</p>
<h5 id="共同注意的transformer层">共同注意的transformer层</h5>
<p>ViLBERT中引入了共同注意的transformer层，该模块为每个模态产生以其他模态为条件的注意力集合特征，实际上是在视觉流中执行以图像为条件的语言注意力，在语言流中执行以语言为条件的图像注意力。</p>
<h5 id="图像表示">图像表示</h5>
<p>从预先训练好的物体检测网络中提取边界框和它们的视觉特征来生成图像区域特征，与文本中的文字不同，图像区域缺乏自然排序，文章采用一个5维的向量对区域进行位置编码，五个维度的元素分别为归一化后的bounding boxes的左上角和右下角的坐标以及图像区域覆盖占比，然后使用映射将位置编码与视觉特征维数匹配，进行相加后得到图像区域特征。使用一个特定的IMG token作为图像序列的开始，并用它的输出表征整个图像。</p>
<h5 id="预训练任务">预训练任务</h5>
<p>训练ViLBERT模型时采用了两个预训练任务，分别是掩蔽多模态建模和多模态对齐预测，如下图所示，</p>
<center>
<img src="/2022/03/08/ViLBERT%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/004.png" width="600px">
<p style="font-family:KaiTi">
图3：ViLBERT预训练任务
</p>
</center>
<p>掩蔽多模态建模任务来自于标准BERT中的掩蔽语言建模任务，屏蔽大约15%的单词和图像区域输入，并要求模型在剩余输入的情况下对屏蔽进行预测。在对图像进行掩蔽时，90%的概率是直接遮挡，另外10%的概率保持不变，文本的掩蔽方案与BERT一致。ViLBERT并不直接预测被掩蔽区域的图像区域特征值（原因：语言往往只能识别视觉内容的高级语义，而不太可能重建准确的图像特征），而是预测对应区域在语义类别上的分布（不预测位置信息），为了监督这一点，文章从用于特征提取的同一预训练检测模型中获取该区域的特征分布，训练模型以最小化这两个分布之间的KL散度。</p>
<p>多模态对齐预测任务必须预测图像和文本是否对齐，即文本是否描述了图像，文章把输出的<span class="math inline">\(h_{IMG}\)</span>和<span class="math inline">\(h_{CLS}\)</span>作为视觉和语言输入的整体表示，借用视觉和语言模型的另一个常见结构，文章将整体表征计算为<span class="math inline">\(h_{IMG}\)</span>和<span class="math inline">\(h_{CLS}\)</span>之间的元素乘积，并添加一个线性层来进行图像和文字是否对齐的二元预测。</p>
]]></content>
      <categories>
        <category>深度学习论文阅读</category>
      </categories>
      <tags>
        <tag>多模态模型</tag>
      </tags>
  </entry>
  <entry>
    <title>test</title>
    <url>/2020/09/06/test/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>
]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer综述论文阅读</title>
    <url>/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近想要研读一下关于transformer变体结构在多模态特征融合时的操作的论文，首先需要广泛地了解一下transformer结构及其变体，于是阅读了复旦大学邱锡鹏教授组里的transformer综述论文，本篇博客详细记录了综述论文中的重点以及本文作者对于这篇论文的理解。 <span id="more"></span></p>
<h3 id="介绍">介绍</h3>
<p>Transformer结构在许多人工智能领域都取得了巨大成功，如自然语言处理、计算机视觉和音频处理领域，到目前，已经提出了大量Transformer结构的变体（又称X-formers），综述论文从三个角度介绍了各种X-former：X-former对于传统Transformer架构的修改、基于Transformer变体的预训练模型以及Transformer变体模型在领域上的应用。</p>
<p>Transformer结构最初是作为一个用于机器翻译的序列到序列模型提出的，后来的工作表明，基于Transformer的预训练模型（PTMs）可以在各种任务上达到最先进的性能。由于Transformer取得的成功，在过去几年内，又有人陆续提出Transformer的变体，主要是在以下几个角度作出改进：</p>
<ol type="1">
<li>模型效率。应用Transformer的一个关键挑战是它在处理长序列时效率低下，这主要是自注意模块中的计算和记忆复杂性导致的，改进方法包括轻量级注意力（如稀疏注意力变体）和采用递归和分层的注意力机制。</li>
<li>模型泛化。由于Transformer是一个灵活的架构，对输入数据的结构偏差几乎不作假设，所以很难在小规模的数据上进行训练，改进方法包括引入结构偏差或正则化，以及在大规模未标记数据上进行预训练。</li>
<li>模型适应性。这项工作的目的是使Transformer适应特定的下游任务和应用。</li>
</ol>
<h3 id="背景">背景</h3>
<h4 id="传统transformer">传统Transformer</h4>
<p>传统的Transformer是一个序列到序列的模型，由一个编码器和一个解码器组成，每个编码器是由<span class="math inline">\(L\)</span>个相同的块堆叠而成。每个编码器块主要是由一个多头注意力模块和一个前馈神经网络组成，为了建立更深层次的模型，在每个块周围采用了残差连接，然后是层归一化操作。与编码器块相比，解码器块在多头自注意力模块和前馈神经网络这件额外插入交叉主义模块。</p>
<blockquote>
<p><strong>需要注意的是，与编码器中的自注意模块不同的是，解码器中的自注意模块被调整为每个位置防止关注后续位置。</strong></p>
</blockquote>
<p>传统Transformer的架构如下图所示，</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/001.png" width="500px">
<p style="font-family:KaiTi">
图1：传统Transformer架构图
</p>
</center>
<h5 id="注意力模块">注意力模块</h5>
<p>Transformer的注意力机制采用QKV模型，计算公式如下，</p>
<p><span class="math display">\[
\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{\top}}{\sqrt{D_{k}}}\right) V=A V
\]</span></p>
<p>在计算过程中需要注意QKV矩阵的维度，<span class="math inline">\(\mathbf{Q} \in \mathbb{R}^{N \times D_{k}}\)</span>，<span class="math inline">\(\mathrm{K} \in \mathbb{R}^{M \times D_{k}}\)</span>，<span class="math inline">\(\mathrm{V} \in \mathbb{R}^{M \times D_{v}}\)</span>，其中<span class="math inline">\(N\)</span>和<span class="math inline">\(M\)</span>代表queries和keys(values)的长度，<span class="math inline">\(D_{k}\)</span>和<span class="math inline">\(D_{v}\)</span>代表keys(queries)和values的维度，</p>
<blockquote>
<p><strong>1. softmax归一化操作按行进行</strong><br> <strong>2. 点积缩放（除以<span class="math inline">\(\sqrt{D_{k}}\)</span>）减轻softmax函数的梯度消失问题</strong></p>
</blockquote>
<p>传统的Transformer模型采用多头注意力机制，将原本的<span class="math inline">\(D_{m}\)</span>维度的queries、keys和values分别映射成<span class="math inline">\(D_{k}\)</span>、<span class="math inline">\(D_{k}\)</span>、<span class="math inline">\(D_{v}\)</span>维，并使用<span class="math inline">\(H\)</span>组学习的投影集。对于每一个投影的query、key和value，根据QKV模型计算公式计算输出，然后，将所有的输出连接起来，并将它们投射到<span class="math inline">\(D_{m}\)</span>的维度表示，多头注意力机制计算公式如下，</p>
<p><span class="math display">\[
\begin{array}{r}
\text { MultiHeadAttn }(\mathbf{Q}, \mathbf{K}, \mathbf{V})=\text { Concat }\left(\text { head }_{1}, \cdots, \text { head }_{H}\right) \mathbf{W}^{O}, \\
\text { where head }_{i}=\text { Attention }\left(\mathbf{Q W}_{i}^{Q}, \mathbf{K W}_{i}^{K}, \mathbf{V W}_{i}^{V}\right) .
\end{array}
\]</span></p>
<p><strong>在Transformer中，有三种注意力机制方式：</strong></p>
<ol type="1">
<li><strong>自注意力机制</strong>。在transformer的编码器中，设置<span class="math inline">\(Q=K=V=X\)</span>，其中<span class="math inline">\(X\)</span>是上一层的输出。<br></li>
<li><strong>掩码自注意力机制</strong>。在transformer解码器中，自注意是受限制的，即每个位置的查询只能注意到该位置之前的所有键值对。为了实现并行训练，通常对非标准化注意力矩阵<span class="math inline">\(\hat{A}=\exp \left(\frac{Q K^{\top}}{\sqrt{D_{k}}}\right)\)</span>应用屏蔽函数，其中非法位置通过设置<span class="math inline">\(\hat{A}_{i j}=-\infty \text { if } i&lt;j\)</span>来进行实现。这种注意方式也被称为自回归注意或因果注意。</li>
<li><strong>交叉注意机制</strong>。交叉注意记住的query是由前一个解码层的输出投影出来的，而key和value是由编码器的输出投影出来的。</li>
</ol>
<h5 id="position-wise前馈神经网络">position-wise前馈神经网络</h5>
<blockquote>
<p><strong>在position-wise前馈神经网络中，参数在不同的位置上是共享的，因此position-wise前馈神经网络也可以理解为两个卷积层，核大小为1。</strong></p>
</blockquote>
<p>position-wise前馈神经网络的计算公式如下所示，</p>
<p><span class="math display">\[
\operatorname{FFN}\left(\mathbf{H}^{\prime}\right)=\operatorname{ReLU}\left(\mathbf{H}^{\prime} \mathbf{W}^{1}+\mathbf{b}^{1}\right) \mathbf{W}^{2}+\mathbf{b}^{2}
\]</span></p>
<p>其中，<span class="math inline">\(\mathbf{H}^{\prime}\)</span>是上一层输出，<span class="math inline">\(\mathbf{W}^{1} \in \mathbb{R}^{D_{m} \times D_{f}}, \mathbf{W}^{2} \in \mathbb{R}^{D_{f} \times D_{m}}, \mathbf{b}^{1} \in \mathbb{R}^{D_{f}}, \mathbf{b}^{2} \in \mathbb{R}^{D_{m}}\)</span>，需要额外注意的是，<strong>一般设置<span class="math inline">\({D_{f}}\)</span>大于<span class="math inline">\({D_{m}}\)</span></strong>。</p>
<h5 id="残差连接和标准化">残差连接和标准化</h5>
<p>为了建立一个深层次模型，transformer在每个模块周围采用了一个残差连接，然后进行层级标准化处理。例如，每一个transformer编码器模块可以表示为如下公式，</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{H}^{\prime} &amp;=\text { LayerNorm }(\text { SelfAttention }(\mathbf{X})+\mathbf{X}) \\
\mathbf{H} &amp;=\text { LayerNorm }\left(\text { FFN }\left(\mathbf{H}^{\prime}\right)+\mathbf{H}^{\prime}\right)
\end{aligned}
\]</span></p>
<h5 id="位置编码">位置编码</h5>
<p>由于transformer没有引入递归或卷积操作，因此对位置信息一无所知（尤其是对于编码器而言），因此需要额外的位置表示来模拟token的排序。</p>
<h4 id="模型用途">模型用途</h4>
<ol type="1">
<li>使用编码器-解码器结构，通常用于序列到序列的建模。</li>
<li>只使用编码器结构，编码器的输出被用作输入序列的表示，通常用于分类或序列标记问题。</li>
<li>只使用解码器结构，其中编码器-解码器交叉注意模块也被移除，通常用于序列生成问题，如语言建模。</li>
</ol>
<h4 id="模型复杂度和参数量分析">模型复杂度和参数量分析</h4>
<p>在假设序列长度为<span class="math inline">\(T\)</span>，维度为<span class="math inline">\(D\)</span>，FFN全连接层维度为<span class="math inline">\(4D\)</span>的情况下，自注意模块和position-wise前馈神经网络模块的复杂度和参数量如下表所示，</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/002.png" width="600px">
</center>
<p>对于transformer结构中自注意模块和前馈神经网络复杂度和参数量的推导，可以参考以下博客：</p>
<p><a href="https://0809zheng.github.io/2021/07/12/efficienttransformer.html" target="_blank">传送门1：https://0809zheng.github.io/2021/07/12/efficienttransformer.html</a> <a href="https://zhuanlan.zhihu.com/p/264749298" target="_blank">传送门2：https://zhuanlan.zhihu.com/p/264749298</a></p>
<h4 id="transformer与其他模型的比较">transformer与其他模型的比较</h4>
<h5 id="对自注意操作的分析">对自注意操作的分析</h5>
<ol type="1">
<li>它具有与全连接层相同的最大路径长度，使其适合于长距离的依赖关系建模，与全连接层相比，它的参数效率更高，在处理可变长度的输入时更加灵活。</li>
<li>由于卷积层的感受野有限，人们通常需要堆叠一个深度网络来拥有一个全局感受野，另一方面，恒定的最大路径长度使自注意能够以恒定的层数来模拟长距离的依赖关系。</li>
<li>相比于循环层，自注意的并行度更高，更擅长长距离建模。</li>
</ol>
<p>下表展示了不同类型层的复杂度分析、最小序列操作数和最大路径长度。</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/003.png" width="600px">
</center>
<h5 id="关于归纳偏置">关于归纳偏置</h5>
<blockquote>
<p>在机器学习中，很多学习算法经常会对学习的问题做一些关于目标函数的必要假设，称为归纳偏置 (Inductive Bias)</p>
</blockquote>
<p>卷积网络通过共享的局部核函数施加了平移不变性和局部性的归纳偏置，循环神经网络通过其马尔科夫结构带来了时间不变性和位置性的归纳偏置，而transformer架构对数据的结构信息几乎不作假设，这使得transformer成为一个通用和灵活的架构，带来的副作用是<strong>容易对小规模的数据进行过度拟合</strong>。另外，transformer可以看作是一个带有完整有向图上所定义的GNN，其中每个输入都可视为图中的一个节点，然而，transformer和GNN之间的主要区别在于transformer没有引入关于如何构造输入数据的先验知识，transformer中的信息传递过程完全依赖于内容的相似性度量。</p>
<blockquote>
<p>卷积网络的平移不变性体现在卷积核共享权重，局部性体现在卷积核大小是有限的；RNN的时间不变性体现在序列顺序中的每个时间步之间都是有关联的。</p>
</blockquote>
<h3 id="对transformer变体的分类">对transformer变体的分类</h3>
<p>到目前为止，人们已经从三个方面改进传统的transformer模型：架构修改、预训练和应用，其中架构修改又分为模块级别的改进和体系级别的改进，下图给出了transformer变体分类说明，</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/004.png" width="600px">
<p style="font-family:KaiTi">
图2：Transformer变体分类
</p>
</center>
<p>详细transformer变体分类如下图所示，</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/005.png" width="600px">
<p style="font-family:KaiTi">
图3：详细Transformer变体分类
</p>
</center>
<h3 id="模块级别改进">模块级别改进</h3>
<h4 id="attention机制">attention机制</h4>
<p>self-attention在实际应用中存在两大挑战：</p>
<ol type="1">
<li>复杂性。在处理长序列时，注意力模块称为瓶颈。</li>
<li>结构性先验。自注意对输入的数据不存在任何结构性偏向，甚至顺序信息也需要从训练数据中学习，因此，不含预训练的transformer在小规模或中等规模的数据上通常容易过拟合。</li>
</ol>
<p>attention机制的改进方向：</p>
<ol type="1">
<li>稀疏注意力机制，将稀疏偏置引入到注意力计算。</li>
<li>线性化注意，将注意力矩阵和特征映射分离，降低至线性复杂度。</li>
<li>原型和显存压缩，减少了查询或键值对的数量，从而减小注意力矩阵大小。</li>
<li>低秩自注意，主要抓住自注意力的低秩性。</li>
<li>带有先验的注意力，主要使用先验注意力分布来补充或替代标准注意力。</li>
<li>改进的多头机制。</li>
</ol>
<h5 id="稀疏注意力机制">稀疏注意力机制</h5>
<p>在标准的自注意机制中，每个token都需要注意其他所有token，但事实上，所学习到的注意力矩阵大多是非常稀疏的，因此，可以通过加入结构性偏差来限制每个query所关注的query-key对的数量，从而降低计算的复杂性。计算公式如下所示，</p>
<p><span class="math display">\[
\hat{\mathbf{A}}_{i j}=\left\{\begin{array}{ll}
\mathbf{q}_{i} \mathbf{k}_{j}^{\top} &amp; \text { if token } i \text { attends to token } j \\
-\infty &amp; \text { if token } i \text { does not attend to token } j
\end{array}\right.
\]</span></p>
<p>根据确定稀疏连接的指标，可以将这些方法分为两类，基于位置的稀疏注意和基于内容的稀疏注意。</p>
<h6 id="基于位置信息的稀疏化注意力">基于位置信息的稀疏化注意力</h6>
<p>在基于位置信息的稀疏化注意力中，注意力矩阵是根据一些预先定义的模式来限制的，尽管这些稀疏模式有不同的形式，但有些可以分解为一些原子的稀疏模式，如下图所示，</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/006.png" width="650px">
<p style="font-family:KaiTi">
图4：原子稀疏注意力模式
</p>
</center>
<ol type="1">
<li>global attention：增加一些全局节点作为节点间信息传播的枢纽，这些全局节点可以注意序列中的所有节点，整个序列也注意这些全局节点。</li>
<li>band attention：利用数据具有很强局部性的特点，限制了每个query对其邻居节点的关注。</li>
<li>dilated attention：通过扩大扩张空隙来获得更大的感受野。</li>
<li>random attention：为了提高非局部信息互动的能力，对每个query随机抽取几条边。</li>
<li>block local attention：这类注意将输入序列分割成几个不重叠的query块，每个query块都与一个本地记忆块相关，一个query块中的所有query都只关注相应记忆块中的key，图4(e)描述了一种常见的情况，即记忆块与相应的query块是相同的。</li>
</ol>
<p>下图展示一些复合稀疏注意力模式，复合稀疏注意力模式通常是原子稀疏注意力模式组合而成的，</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/007.png" width="550px">
<p style="font-family:KaiTi">
图5：复合稀疏注意力模式
</p>
</center>
<p>除了上述模式外，一些现有的研究还探索了针对特定数据类型的扩展稀疏模式。对于文本数据，BP-Transformer构建了一个二叉树，其中所有的token是叶子节点，内部节点是包含许多token的跨度节点，是分层组织的；对于视觉数据，有Image Transformer和Axial Transformer。三种transformer变体的扩展稀疏注意力模式如下图所示，</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/008.png" width="550px">
<p style="font-family:KaiTi">
图6：扩展稀疏注意力模式
</p>
</center>
<h6 id="基于内容的稀疏注意力">基于内容的稀疏注意力</h6>
<p>构建基于内容的稀疏图的一个直接方法是选择那些可能与给定query有较大相似性分数的key。Routing Transformer使用K-means聚类算法，将query和key都集中在同一组中心点向量上，每个query只与其处在相同cluster下的key进行交互。Reformer采用LSH哈希方法来为每个query选择key-value，其主要思想是对query和key哈希，分到多个桶内，在同一个桶内的query、key参与交互。SAC将输入序列视为一个图，并学习构建注意力边，以使用自适应稀疏连接改善特定任务的性能，其中边预测器是通过强化学习来训练的。Sparse Sinkhorn Attention首先将query和key通过排序网络控制分为几个块，并为每个query块分配一个key块，每个query只允许关注被分配给其相应块中的key。</p>
<h5 id="线性注意力">线性注意力</h5>
<p>线性化注意力是一类用<span class="math inline">\(\phi(Q) \phi(K)^{\top}\)</span>近似或替换非标准化注意力矩阵<span class="math inline">\(\exp \left(Q K^{\top}\right)\)</span>的方法，其中<span class="math inline">\(\phi\)</span>是按行方式应用的特征图，因此，非归一化注意力矩阵的计算可以通过计算<span class="math inline">\(\phi(Q)\left(\phi(K)^{\top} V\right)\)</span>来线性化，如下图所示，</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/009.png" width="600px">
<p style="font-family:KaiTi">
图7：标准注意力和线性注意力对比
</p>
</center>
<p>该模型通过聚合(由特征映射的)key和value的外积表示的关联来维护内存矩阵，然后通过将内存矩阵与具有适当归一化的特征映射查询相乘来检索值，这种方法有两个关键组件，包括特征图和聚合规则。</p>
<h5 id="查询原型和键值内存压缩">查询原型和键值内存压缩</h5>
<p>除了使用稀疏注意和基于内核的线性化注意，人们还可以通过减少查询(query)或键值对的数量来降低注意的复杂性。使用原型查询的注意力机制和压缩键值内存的注意力机制如下图所示：</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/010.png" width="600px">
<p style="font-family:KaiTi">
图8：查询原型和键值内存压缩
</p>
</center>
<ol type="1">
<li><p><strong>使用原型查询的注意力机制</strong>：在查询原型中，几个查询的原型作为计算注意力分布的主要来源。该模型或者将这些注意力分布复制到所代表的查询的位置上，或者使用离散的均匀分布来填充这些位置。例如clustered attention将查询分为几个集群，然后计算集群中心点的注意力分布，一个集群中的所有查询都共享相应中心点计算的注意力分布；Informer使用明确的查询稀疏度测量法从查询中选择原型，然后，在查询稀疏度测量下，只计算top-u查询的注意力分布，其他查询被分配为离散的均匀分布。</p></li>
<li><p><strong>压缩键值内存的注意力机制</strong>：可以通过在应用注意力机制之前减少键值对的数量来降低复杂度。例如，Liu等人提出了使用分层卷积的方法减少键和值的数量；Set Transformer和Luna使用一些外部可训练的全局节点总结来自输入的信息，然后将总结后的表征作为输入注意的压缩键值内存。</p></li>
</ol>
<h5 id="低秩自注意">低秩自注意</h5>
<p>一些经验和理论分析报告称，自注意矩阵通常是低秩的，这个属性的含义是双重的，一是低秩属性可以用参数化来显式建模，二是可以用低秩近似值代替自注意力矩阵。</p>
<h5 id="带有先验的注意力">带有先验的注意力</h5>
<p>传统意义上，注意力分布是由输入产生的，作为一种广义的情况，注意力分布也可以来自其他来源，我们称之为先验，先验注意力分布可以是对输入产生的分布的补充或替代，我们把这种注意力的表述抽象为带有先验的注意力。在大多数情况下，两种注意力分布的融合可以通过计算对应于先验注意力分布和输入产生的注意力分布的加权和来完成，然后再应用softmax。带有先验的注意力如下图所示，</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/011.png" width="600px">
<p style="font-family:KaiTi">
图9：带有先验的注意力
</p>
</center>
<ol type="1">
<li><p>模型位置先验：一些类型的数据（如文本）可以表现出对位置性的强烈偏好，这个属性可以显式编码为先验注意力。一个简单的方法是在位置上使用一个高斯分布，具体来说，我们可以将输入生成的注意力分布与一些高斯密度相乘，然后重新规范化，这相当于在生成的注意力分数中加入偏置项。</p></li>
<li><p>底层模块先验：在transformer架构中，经常观察到相邻层的注意力分布相似，因此，很自然地将前一层的注意力分布作为下一层注意力计算的先验。例如，Predictive Attention Transformer提出将二维卷积层应用于以前的注意力分数，并将最终的注意力分数计算为输入生成的注意力分数和卷积分数的凸组合。</p></li>
<li><p>多任务适配器先验：适配器是依赖于任务的训练模块，它们附加在预训练网络的特定位置，用于跨任务高效参数共享。</p></li>
<li><p>仅注意力先验：一些工作探索了使用独立于输入之间成对交互的注意力分布，换句话说，他们的模型只利用了先验注意力分布。例如，You等人利用高斯分布作为注意力计算的硬编码注意力分布，完全放弃了输入生成的注意力，只使用高斯分布来计算注意力，在这种方法中，均值和方差被设计为超参数，实验表明，硬编码的注意力，当只应用于自注意力时，可以在机器翻译任务中取得与基线模型相当的性能。</p></li>
</ol>
<h5 id="改进的多头机制">改进的多头机制</h5>
<p>多头注意能够在不同的位置共同注意来自不同表征子空间的信息，然而，没有任何机制可以保证不同的注意头确实捕捉到不同的特征。</p>
<ol type="1">
<li><p>头部行为建模：一系列工作致力于通过引入更复杂的机制来改进多头机制，以指导不同注意力头的行为或允许注意力头之间的互动。例如，Li等人在损失函数中引入了一个辅助的分歧正则化项，以鼓励不同注意力头之间的多样性，两个正则化项分别用于最大化输入子空间和输出表征的余弦距离，而另一个正则化项则是通过相应注意力矩阵的逐元相乘来分散多个头所关注的位置。</p></li>
<li><p>跨度受限的多头：原版注意力采用完全注意力跨度假设，其中查询可以关注所有键值对，然而，经常观察到，一些头主要将注意力集中在局部环境中，而其他一些头则关注更广泛的环境，因此，限制注意力的跨度可能是有益的。限制注意力跨度可以表示为将每个注意力分布值与一个掩码值相乘，然后重新归一，传统的注意力为所有距离分配掩码值1。Sukhbaatar采取一个可学习的注意力跨度，即适用一个可学习的标量<span class="math inline">\(z\)</span>和一个超参数<span class="math inline">\(R\)</span>来生成mask进而控制跨度。Multi-Scale Transformer采用了固定的跨度，不同层的不同头使用不同的最大跨度，一般来说，底层网络的最大跨度较小，上层网络的最大跨度较大。三种跨度掩码函数如下图所示，</p></li>
</ol>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/012.png" width="700px">
<p style="font-family:KaiTi">
图10：三种跨度掩码函数
</p>
</center>
<ol start="3" type="1">
<li>精细聚合的多头：在每个注意力头计算其输出表示后，原版多头注意力将这些表示连接起来，然后对连接后的表示应用线性变换以获得最终的输出表示。有研究提出说，这种简单的逐个聚合范式并没有充分利用多头注意力的表现力，而使用更为复杂的聚合更为可取。因此有人提出了使用为胶囊网络设计的路由方法，注意力头的输出首先转化为输入胶囊，然后经过迭代路由过程得到输出胶囊，然后将输出胶囊连接起来作为多头注意力的最终输出。</li>
</ol>
<h4 id="其他模块级别改进">其他模块级别改进</h4>
<h5 id="位置表示">位置表示</h5>
<p>很容易验证卷积和循环网络不是置换等变的。 然而，Transformer 中的自注意力模块和位置前馈层都是置换等变的，这可能在建模时成为一个问题，而不是需要输入结构的集合输入问题。 例如，在对文本序列建模时，单词的顺序很重要，因此在 Transformer 架构中正确编码单词的位置至关重要。 因此，需要额外的机制将位置信息注入到 Transformer 中。 一种常见的设计是首先使用向量表示位置信息，然后将向量作为附加输入注入模型。</p>
<h6 id="绝对位置表示">绝对位置表示</h6>
<p>在传统Transformer中，位置信息被编码为绝对正弦位置编码，在位置编码完毕后，将序列中每个位置的位置编码加入到token的词嵌入中，然后送入Transformer。</p>
<p>另一种表示绝对位置的方法是为每个位置学习一组位置嵌入，与手工制作的位置嵌入相比，学习的嵌入更加灵活，因为位置表示可以通过反向传播适应任务，但是，嵌入的数量被限制在训练前确定的最大序列长度内，这使得这种方法不再是归纳性的，也就是说，不能处理比训练时看到的序列更长的序列。</p>
<p>合并绝对位置表示的基本方法是在token嵌入中添加位置编码。然而，当输入信号在层间传播时，位置信息可能会在上层丢失。后来的工作发现，将位置表示添加到每个Transformer层的输入中是有益的。</p>
<h6 id="相对位置表示">相对位置表示</h6>
<p>另一系列工作侧重于表示token之间的位置关系，而不是单个token的位置，直觉认为，在自注意力中输入元素（方向和距离）之间的成对位置关系可能比元素的位置更有益。遵循这一原则的方法称为相对位置表示。</p>
<h6 id="其他表示">其他表示</h6>
<p>一些研究已经探索使用包含绝对和相对位置信息的混合位置表示。 Transformer with Untied Position Encoding (TUPE) 将注意力分数的计算重新设计为内容到内容项、绝对位置到位置项和表示相对位置关系的偏置项的组合。</p>
<h6 id="没有显式编码的位置表示">没有显式编码的位置表示</h6>
<p>Wang 等人没有明确引入额外的位置编码，建议通过将嵌入推广到位置上的连续（复值）函数来对词嵌入中的位置信息进行编码。</p>
<h6 id="transformer-decoder的位置表示">Transformer decoder的位置表示</h6>
<p>在解码器的交叉注意中采取了掩码的自注意，而掩码的自注意不是置换等变的，因此，仅利用Transformer解码器的模型具有在不包含显式位置表示的情况下感知位置信息的潜力。语言建模任务的一些实证结果证实了这一点，作者发现删除位置编码甚至可以提高性能。</p>
<h5 id="层归一化">层归一化</h5>
<p>层归一化（LN）和残差连接被认为是一种稳定深度网络训练的机制（例如，缓解不理想的梯度和模型退化的问题），目前已经有一些研究致力于分析和改进LN模块。</p>
<h6 id="ln的放置">LN的放置</h6>
<p>在传统Transformer中，LN层位于残差块之间，称为post-LN，后来的Transformer实现将LN层放在注意力或FFN之前的残差连接内，在最后一层之后有一个额外的LN来控制最终的输出大小，这被称为pre-LN，post-LN和pre-LN的架构如下图所示，</p>
<center>
<img src="/2022/02/26/Transformer%E7%BB%BC%E8%BF%B0%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/013.png" width="600px">
<p style="font-family:KaiTi">
图11：post-LN和pre-LN的架构对比
</p>
</center>
<p>另外，warm-up阶段可以从pre-LN Transformer上安全地去除，而不必担心输出层附近梯度过大导致训练不稳定的情况。</p>
]]></content>
      <categories>
        <category>深度学习论文阅读</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态情感分析综述</title>
    <url>/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>多模态情感分析是一个越来越受欢迎的研究领域，它将传统的基于文本的情感分析任务扩展到多模态的情景下，多模态包括文本、视频和语音模态，以往的情感分析任务通常聚焦于单个模态，但在某些情况下，仅仅通过文本模态来分析说话人的情感是不够的，如以下语句 <span id="more"></span></p>
<blockquote>
<p>The movie is sick.</p>
</blockquote>
<p>这句话本身所要表达的意思是模棱两可的，但如果说话者在说这句话的同时也在微笑，那么它就会被认为是积极的（positive），反过来说，如果说话者在说这句话的同时皱着眉头，则这句话被认为是消极的（negative），以上例子说明了双模态信息之间的互动，其中微笑和皱着眉头等信息能够在视频模态中体现出来。然后我们可以继续加入语音模态从而考虑三模态的情况，当说话声音较大时，这句话的积极情感会进一步增强，但加入使用fair替换掉sick这个单词，虽然同样是大声说话的情景，但考虑到fair这个词的强烈影响，这句话的情感并没有因为大声说话而产生巨大变化。以上例子说明了模态间信息交互的复杂性，但不可置疑的是，视频和语音模态中可能包含文本模态中的互补信息，因此，在多模态场景下进行情感分析任务更具有可信性。</p>
<center>
<img src="/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/001.png" width="400px">
<p style="font-family:KaiTi">
图1：模态之间信息的互动
</p>
</center>
<p>现阶段的多模态情感分析任务，大多站在如何有效地将多模态的特征信息进行融合这一角度考虑问题，目的是排除与情感分析任务无关的噪声数据，最大化利用与情感分析任务相关的多模态数据，包括单模态内的数据交互与模态间的数据交互，最终达到分析情感极性的目标。本文主要就多模态数据集和多模态特征的融合方法进行介绍。</p>
<h3 id="数据集">数据集</h3>
<h3 id="多模态特征融合方法">多模态特征融合方法</h3>
<h4 id="早期融合">早期融合</h4>
<p>早期融合，也被称为特征级别的融合，直接将来自不同模式的特征表示连接成一个单一的表示，这是一种最直观的方法。下图展示了早期融合的具体操作。</p>
<center>
<img src="/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/002.png" width="200px">
<p style="font-family:KaiTi">
图2：早期融合具体操作
</p>
</center>
<p>但是，由于来自不同模态的特征表示可能存在巨大差异，我们必须考虑时间同步问题，即不同模态的特征表示必须在时间层面上进行对齐，以便在融合前将这些特征表示转化为相同的格式，所以在某一个模态或某几个模态有信息缺失的情况下，早期融合的方法不能对模态间的互动进行有效建模。 另外，因为早期融合直接将不同模态的特征表示进行连接，可能会造成融合特征表示较为复杂的情况，最终会导致过拟合的发生。</p>
<h4 id="后期融合">后期融合</h4>
<p>后期融合，也被称为决策级别的融合，通常是整合来自每一个单一模态的预测结果，即首先利用每一个模态的数据信息进行预测，再将每一个模态的预测结果进行整合，流行的整合方法包括平均法、投票法和信号差异法。</p>
<p>后期融合的优点包括：</p>
<ol type="1">
<li>灵活性，可以为每个模态的数据选择最佳的分类器。</li>
<li>鲁棒性，当某些模态的数据有缺失时，后期融合的方法依然可以工作。</li>
</ol>
<p>但是后期融合的方法也有相当大的缺点，即不能够有效学习模态间的信息交互，不同模态数据之间的相关性和差异性被忽略。</p>
<h4 id="基于张量的融合">基于张量的融合</h4>
<p>基于张量的融合方法建立了一个融合层，具体融合方法为在三维向量场中将每种模态的向量表示进行外积操作得到融合向量表示，操作方法如图所示，</p>
<center>
<img src="/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/003.png" width="350px">
<p style="font-family:KaiTi">
图3：基于张量的融合方法
</p>
</center>
<p>需要注意的是，不同模态的特征在进行融合时还需要保留原模态的特征，这样可以更好地利用单模态内的信息，基于张量的融合方法也考虑到这一点，在每一个模态的向量末尾连接1，这样在进行外积的同时还能够保留原有模态的特征，下图以视频模态和文本模态的特征融合为例说明了这一点，</p>
<center>
<img src="/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/004.png" width="300px">
<p style="font-family:KaiTi">
图4：视频模态和文本模态的特征融合
</p>
</center>
<p>可以使用如下公式来表示文本模态、语音模态和视频模态的融合过程，其中<span class="math inline">\(\mathbf{z}^{m}\)</span>表示融合特征向量，<span class="math inline">\(\mathbf{z}^{l}\)</span>表示文本模态特征向量，<span class="math inline">\(\mathbf{z}^{v}\)</span>表示视频模态特征向量，<span class="math inline">\(\mathbf{z}^{a}\)</span>表示语音模态特征向量，可以结合图4来理解以下公式，其中<span class="math inline">\(\mathbf{z}^{l} \otimes \mathbf{z}^{v}\)</span>、<span class="math inline">\(\mathbf{z}^{a} \otimes \mathbf{z}^{v}\)</span>和<span class="math inline">\(\mathbf{z}^{l} \otimes \mathbf{z}^{a}\)</span>表示双模态之间的信息互动，<span class="math inline">\(\mathbf{z}^{l} \otimes \mathbf{z}^{v} \otimes \mathbf{z}^{a}\)</span>表示三模态之间的信息互动。</p>
<p><span class="math display">\[
\mathbf{z}^{m}=\left[\begin{array}{c}
\mathbf{z}^{l} \\
1
\end{array}\right] \otimes\left[\begin{array}{c}
\mathbf{z}^{v} \\
1
\end{array}\right] \otimes\left[\begin{array}{c}
\mathbf{z}^{a} \\
1
\end{array}\right]
\]</span></p>
<p>基于张量的融合方法显式地建模了单模态、双模态、三模态之间的信息互动，并且虽然融合特征向量是高维向量，但由于单模态特征之间是通过外积操作来进行融合的，没有可学习的参数，所以不用考虑过拟合的问题。</p>
<h4 id="低秩多模态融合方法">低秩多模态融合方法</h4>
<p>以上我们已经介绍了基于张量的融合方法，但这种方法往往会因为将单模态向量转化为融合张量而导致维度和计算复杂性的指数级增长（外积操作所致），为了解决基于张量的多模态融合方法计算效率差的问题，提出了一种低秩多模态融合的方法，主要是利用了将张量和权重并行分解的思想。</p>
<p>首先我们需要明确输出<span class="math inline">\(h\)</span>的计算方法，如以下公式所示，</p>
<p><span class="math display">\[
h=g(\mathcal{Z} ; \mathcal{W}, b)=\mathcal{W} \cdot \mathcal{Z}+b, h, b \in \mathbb{R}^{d_{y}}
\]</span></p>
<p>其中<span class="math inline">\(\mathcal{Z}\)</span>为融合张量，低秩多模态融合方法首先将权重<span class="math inline">\(\mathcal{W}\)</span>进行分解为如下形式,</p>
<p><span class="math display">\[
\mathcal{W}=\sum_{i=1}^{r} \bigotimes_{m=1}^{M} \mathbf{w}_{m}^{(i)}
\]</span></p>
<p>可以首先尝试理解一下作者这样分解的目的，即为了利用类似于分配律的原理让外积操作变为对应元素的乘积，最终达到每种模态数据乘以对应权重，然后再进行element wise（对应元素乘积）的操作的目标，以下我们可以尝试证明一下，</p>
<p><span class="math display">\[
\begin{aligned}
h &amp;=\left(\sum_{i=1}^{r} \bigotimes_{m=1}^{M} \mathbf{w}_{m}^{(i)}\right) \cdot \mathcal{Z} \\
&amp;=\sum_{i=1}^{r}\left(\bigotimes_{m=1}^{M} \mathbf{w}_{m}^{(i)} \cdot \mathcal{Z}\right) \\
&amp;=\sum_{i=1}^{r}\left(\bigotimes_{m=1}^{M} \mathbf{w}_{m}^{(i)} \cdot \bigotimes_{m=1}^{M} z_{m}\right) \\
&amp;=\Lambda_{m=1}^{M}\left[\sum_{i=1}^{r} \mathbf{w}_{m}^{(i)} \cdot z_{m}\right]
\end{aligned}
\]</span></p>
<p>其中公式中的<span class="math inline">\(\Lambda\)</span>符号表示对应元素乘积的操作，特别地，有以下记法：<span class="math inline">\(\Lambda_{t=1}^{3} x_{t}=x_{1} \circ x_{2} \circ x_{3}\)</span>，最终可以使用下图来表示低秩多模态融合方法，</p>
<center>
<img src="/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/005.png" width="550px">
<p style="font-family:KaiTi">
图5：低秩多模态融合方法
</p>
</center>
<h4 id="基于神经网络的融合方法">基于神经网络的融合方法</h4>
<p>基于神经网络的融合采用了一种直接和直观的策略，通过神经网络融合不同模态的特征表示。基于注意力的融合使用注意力机制来获得一组具有标量权重的特征表示的加权和，这些标量权重是由一个注意力模块动态学习的。还有一些融合方法参考了当前比较流行的Transformer和BERT结构的思想，这些使用深度模型的融合方法能够以端到端的方式从大量的数据中学习，具有良好的性能，但也存在可解释性低的问题。</p>
<h5 id="基于注意力机制的融合方法">基于注意力机制的融合方法</h5>
<p>注意力机制被用于多模态融合是很容易想到的操作，注意力机制天然地能够发掘源模态和目标模态的联系，从而生成注意力权重，通过乘积进一步加强目标模态的特征表示，注意力机制很适用于发掘模态之间的共同特征，但对于发掘模态的特有特征就显得有些力不从心。这里我们以记忆融合网络（MFN）为例来探索注意力机制在多模态融合方面的应用。</p>
<p>注意力机制通常不会单独应用在多模态特征融合中，可能还会结合其他结构，如MFN由三个主要部分组成，分别是LSTM系统、Delta-Memory注意力网络、多模态门控记忆，其中LSTM系统有多个长短期记忆网络（LSTM）组成，每个模态对应一个LSTM网络，LSTM对模态内的信息的交互进行建模，或者说对每个时间步的模态信息进行记忆；Delta-Memory注意力网络是一种特殊的注意力机制，旨在发现LSTM系统中不同模态记忆间的横向交互关系；多模态门控记忆结构是一种统一的记忆存储，存储随着时间步推移的跨模态信息交互，总结下来，LSTM结构致力于模态内信息的建模，Delta-Memory注意力网络和多模态门控记忆结构致力于模态间信息的建模，模型总体结构如下所示，</p>
<center>
<img src="/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/008.png" width="500px">
<p style="font-family:KaiTi">
图6：记忆融合网络（MFN）的整体架构
</p>
</center>
<p>Delta-Memory注意力网络截取<span class="math inline">\(t-1\)</span>和<span class="math inline">\(t\)</span>两个时间步的LSTM系统输出信息，目的是为了防止重复的跨模态交互信息被赋高权重的情况，如果有了两个时间步的模态信息之后，就可以将两个时间步的信息进行比较从而将高系数分配给那些将要变化的模态信息，文中指出，理想情况下，在LSTM系统的记忆状态发生变化之前，每个跨模态交互只分配一次高系数。Delta-Memory注意力网络中的计算公式如下所示，首先计算出注意力权重系数，再将系数乘以原模态特征表示。</p>
<p><span class="math display">\[
\begin{gather*}
a^{[t-1, t]}=\mathcal{D}_{a}\left(c^{[t-1, t]}\right) \\
\hat{c}^{[t-1, t]}=c^{[t-1, t]} \odot a^{[t-1, t]}
\end{gather*}
\]</span></p>
<p>多模态门控记忆结构存储了一段时间内跨模态信息交互的历史，包括两个门，分别是保持门和更新门，其中保持门分配上一个时间步的记忆，更新门根据更新建议（或称为当前时间步状态）来进行更新，计算公式如下所示，</p>
<p><span class="math display">\[
\begin{gather*}
\hat{u}^{t}=\mathcal{D}_{u}\left(\hat{c}^{[t-1, t]}\right) \\
\gamma_{1}^{t}=\mathcal{D}_{\gamma_{1}}\left(\hat{c}^{[t-1, t]}\right), \gamma_{2}^{t}=\mathcal{D}_{\gamma_{2}}\left(\hat{c}^{[t-1, t]}\right) \\
u^{t}=\gamma_{1}^{t} \odot u^{t-1}+\gamma_{2}^{t} \odot \tanh \left(\hat{u}^{t}\right)
\end{gather*}
\]</span></p>
<h5 id="多模态transformer融合方法">多模态Transformer融合方法</h5>
<p>这里介绍的多模态Transformer融合方法出自<em>Multimodal Transformer for Unaligned Multimodal Language Sequences</em>一文，文章提出了MulT结构，主要应用于非对齐多模态语言序列场景。相关研究表明，在对多模态的语言时间序列数据进行建模时主要存在两个挑战：</p>
<ol type="1">
<li>由于每种模态序列的采样率不同，导致数据没有在时间层面上对齐。</li>
<li>不同模态的元素之间存在长距离依赖的现象。</li>
</ol>
<p>文章中提出的MulT结构以端到端的方法解决了上述问题。MulT结构以跨模态的Transformer作为主要结构来建模模态与模态（双模态）之间的关系，具体来说，每个跨模态Transformer通过学习两个模态之间的注意力，用另一个源模态的低级特征反复强化目标模态，以视频模态和文本模态为例，第一种情况下，以视频模态为源模态，以文本模态为目标模态，在每一个跨模态的注意力机制块中，将源模态特征向量作为注意力机制的<span class="math inline">\(Q\)</span>，将目标模态特征向量作为注意力机制的<span class="math inline">\(K\)</span>、<span class="math inline">\(V\)</span>，经过注意力机制计算得到注意力权重，将权重乘以目标模态特征向量得到强化后的目标模态特征向量，计算公式如下所示，</p>
<p><span class="math display">\[
\text { Attention }(\mathrm{Q}, \mathrm{K}, \mathrm{V})=\operatorname{softmax}\left(\frac{\mathrm{QK}^{\mathrm{T}}}{\sqrt{\mathrm{d}_{\mathrm{k}}}}\right) \mathrm{V}
\]</span></p>
<p>实际情况下采用的多为多头注意力机制；第二种情况下，以文本模态为源模态，以视频模态为目标模态，其他计算过程相同。跨模态的注意力机制块的堆叠组成了跨模态的Transformer结构，另外，这里只着重强调了跨模态的注意力机制块中的跨模态的注意力机制计算细节，跨模态的注意力机制块除了交叉注意力结构，还包括前馈神经网络等结构。跨模态的注意力机制块结构如下所示，</p>
<center>
<img src="/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/006.png" width="300px">
<p style="font-family:KaiTi">
图7：跨模态注意力机制块结构
</p>
</center>
<p>MulT的整体架构如下图所示，在这里我们只关注模态信息融合的部分，即架构的中间部分，可以从图中看到，在完成特征向量的处理之后，将两个模态的特征向量分别作为源模态和目标模态输入到跨模态的Transformer结构中，两个Transformer的输出进行连接，再输入到Transformer结构中，不同的是，跨模态的Transformer中进行的主要是交叉注意力计算，而上部的Transformer中进行的主要是自注意计算。架构的底部和顶部在这里不作主要关注，只需要明确架构的底部为特征向量的处理，架构的顶部为下游任务的适应。</p>
<center>
<img src="/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/007.png" width="350px">
<p style="font-family:KaiTi">
图8：MulT的整体架构
</p>
</center>
<h5 id="基于神经网络的融合方法在可解释性方面的改进">基于神经网络的融合方法在可解释性方面的改进</h5>
<p>一般的基于神经网络的融合方法在可解释性方面都表现较差，所以出现了一些提高可解释性的尝试，现有大多数的尝试是在挖掘共同和独特信息方面的改进。一些框架可以从多模态特征表示中提取公共信息，同时获取一些独特信息，这里的独特信息通常是指特定于模态的信息，最后再通过融合层将共同信息和独特信息进行整合。</p>
<p>将DeepCU结构作为示例进行说明，DeepCU包括两个子网络，包括可以获取模态特性的独特子网络，以及由深度卷积张量网络组成的共同子网络。DeepCU可以通过两个子网络获取到互补的信息，进而通过融合层进行信息整合。DeepCU框架示意图如下所示，</p>
<center>
<img src="/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/009.png" width="500px">
<p style="font-family:KaiTi">
图9：DeepCU的整体架构
</p>
</center>
<p>框架示意图左边是TFN和LMF架构的示意图，DeepCU相较于TFN和LMF更具表现力，因为它在共同子网络中捕获了非线性的多模态交互关系，在独特子网络中不会了分解的非线性特征关系，缓解了缺失值场景，增强了模型的泛化能力。</p>
<p>首先介绍独特子网络获得特定于模态信息的方法，从三个模态提取潜在特征之后，为了能对单模态中信息与信息的交互进行建模，这里采取的是分解机的方法，采用分解机的另一个好处是可以缓解缺失值场景，分解机公式如下所示，</p>
<p><span class="math display">\[
\hat{y}_{F M(\boldsymbol{x})}=w_{0}+\sum_{i=1}^{n} \boldsymbol{w}_{i} \boldsymbol{x}_{i}+\sum_{i=1}^{n} \sum_{j=i+1}^{n} \boldsymbol{v}_{i}^{T} \boldsymbol{v}_{j} \cdot \boldsymbol{x}_{i} \boldsymbol{x}_{j}
\]</span></p>
<p>然后我们对共同子网络进行介绍。共同子网络首先将三个模态的潜在特征进行外积，得到联合表示张量，类似于TFN的做法，其中张量的每个元素代表融合模态元素之间的相互作用强度，然后我们在这些张量上运用卷积操作，因为卷积核是非线性的特征提取器，所以比前馈层的泛化效果更好，并且能够有效降低复杂度，最后再将卷积操作输出输入到全连接层中。融合层的操作较为简单，只采取了简单的连接和转置操作。</p>
<p>上文提到过尝试挖掘共同和独特信息方面的改进，介绍了在挖掘模态共同和独特信息方面的方法，但是挖掘独特信息并不一定指模态独特信息，Deep-HOSeq架构的独特子网络挖掘的是时间步上的独特信息，旨在发现时间与语义观点上的协作，以下是Deep-HOSeq整体架构示意图，</p>
<center>
<img src="/2022/02/11/%E5%A4%9A%E6%A8%A1%E6%80%81%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E7%BB%BC%E8%BF%B0/010.png" width="500px">
<p style="font-family:KaiTi">
图10：Deep-HOSeq的整体架构
</p>
</center>
<p>Deep-HOSeq处理独特子网络的方法是，将每个时间步的各个模态的向量进行外积操作，再进行卷积操作，得到每个时间步的独特信息，经过sum-pooling进行相加，得到独特向量。Deep-HOSeq处理共同子网络和DeepCU处理共同子网络的方法类似。</p>
]]></content>
      <categories>
        <category>深度学习论文阅读</category>
      </categories>
      <tags>
        <tag>多模态情感分析</tag>
      </tags>
  </entry>
  <entry>
    <title>LibRec学习笔记（二）：SVD++算法</title>
    <url>/2022/04/04/LibRec%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89-SVD-%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>上一篇我们具体介绍了BiasedMF算法在LibRec库中的实现，实际上是为了本篇介绍SVD++算法实现做铺垫，在代码中我们也可以看到，<code>SVDPlusPlusRecommender</code>类继承了<code>BiasedMFRecommender</code>类，本篇主要也是从三个方面展开，分别是预测公式、损失函数公式和更新公式。 <span id="more"></span> <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> net.librec.recommender.cf.rating;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> net.librec.annotation.ModelData;</span><br><span class="line"><span class="keyword">import</span> net.librec.common.LibrecException;</span><br><span class="line"><span class="keyword">import</span> net.librec.math.structure.DenseMatrix;</span><br><span class="line"><span class="keyword">import</span> net.librec.math.structure.DenseVector;</span><br><span class="line"><span class="keyword">import</span> net.librec.math.structure.SequentialSparseVector;</span><br><span class="line"><span class="keyword">import</span> net.librec.math.structure.VectorBasedDenseVector;</span><br><span class="line"><span class="keyword">import</span> net.librec.math.structure.Vector.VectorEntry;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ModelData(&#123;&quot;isRating&quot;, &quot;svdplusplus&quot;, &quot;userFactors&quot;, &quot;itemFactors&quot;, &quot;userBiases&quot;, &quot;itemBiases&quot;, &quot;impItemFactors&quot;, &quot;trainMatrix&quot;&#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SVDPlusPlusRecommender</span> <span class="keyword">extends</span> <span class="title">BiasedMFRecommender</span> </span>&#123;</span><br><span class="line">    <span class="keyword">protected</span> DenseMatrix impItemFactors;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">double</span> regImpItem;</span><br><span class="line">    <span class="keyword">private</span> DenseVector factorVector;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SVDPlusPlusRecommender</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">()</span> <span class="keyword">throws</span> LibrecException </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.setup();</span><br><span class="line">        <span class="keyword">this</span>.regImpItem = <span class="keyword">this</span>.conf.getDouble(<span class="string">&quot;rec.impItem.regularization&quot;</span>, <span class="number">0.015D</span>);</span><br><span class="line">        <span class="comment">// 物品隐因子偏置向量 对应公式中的y</span></span><br><span class="line">        <span class="keyword">this</span>.impItemFactors = <span class="keyword">new</span> DenseMatrix(<span class="keyword">this</span>.numItems, <span class="keyword">this</span>.numFactors);</span><br><span class="line">        <span class="comment">// 物品隐因子偏置向量初始化</span></span><br><span class="line">        <span class="keyword">this</span>.impItemFactors.init((<span class="keyword">double</span>)<span class="keyword">this</span>.initMean, (<span class="keyword">double</span>)<span class="keyword">this</span>.initStd);</span><br><span class="line">        <span class="keyword">this</span>.factorVector = <span class="keyword">new</span> VectorBasedDenseVector(<span class="keyword">this</span>.numFactors);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">trainModel</span><span class="params">()</span> <span class="keyword">throws</span> LibrecException </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> iterationStep = <span class="number">1</span>; iterationStep &lt;= <span class="keyword">this</span>.numIterations; ++iterationStep) &#123;</span><br><span class="line">            <span class="keyword">this</span>.loss = <span class="number">0.0D</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> userIndex = <span class="number">0</span>; userIndex &lt; <span class="keyword">this</span>.numUsers; ++userIndex) &#123;</span><br><span class="line">                SequentialSparseVector userVector = <span class="keyword">this</span>.trainMatrix.row(userIndex);</span><br><span class="line">                <span class="keyword">if</span> (userVector.size() != <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">double</span>[] steps = <span class="keyword">new</span> <span class="keyword">double</span>[<span class="keyword">this</span>.numFactors];</span><br><span class="line">                    <span class="keyword">this</span>.factorVector.assign((indexx, value) -&gt; &#123;</span><br><span class="line">                        <span class="keyword">return</span> <span class="number">0.0D</span>;</span><br><span class="line">                    &#125;);</span><br><span class="line">                    Iterator var5 = userVector.iterator();</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">while</span>(var5.hasNext()) &#123;</span><br><span class="line">                        VectorEntry vectorEntry = (VectorEntry)var5.next();</span><br><span class="line">                        <span class="keyword">this</span>.factorVector.assign((indexx, value) -&gt; &#123;</span><br><span class="line">                            <span class="keyword">return</span> <span class="keyword">this</span>.impItemFactors.row(vectorEntry.index()).get(indexx) + value;</span><br><span class="line">                        &#125;);</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">double</span> scale = Math.pow((<span class="keyword">double</span>)userVector.getNumEntries(), -<span class="number">0.5D</span>);</span><br><span class="line">                    <span class="keyword">this</span>.factorVector.assign((indexx, value) -&gt; &#123;</span><br><span class="line">                        <span class="keyword">return</span> value * scale;</span><br><span class="line">                    &#125;);</span><br><span class="line">                    Iterator var7 = userVector.iterator();</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">double</span> factor;</span><br><span class="line">                    <span class="keyword">while</span>(var7.hasNext()) &#123;</span><br><span class="line">                        VectorEntry vectorEntry = (VectorEntry)var7.next();</span><br><span class="line">                        <span class="keyword">int</span> itemIndex = vectorEntry.index();</span><br><span class="line">                        <span class="keyword">double</span> error = vectorEntry.get() - <span class="keyword">this</span>.predict(userIndex, itemIndex, <span class="keyword">this</span>.factorVector);</span><br><span class="line">                        <span class="keyword">this</span>.loss += error * error;</span><br><span class="line">                        factor = <span class="keyword">this</span>.userBiases.get(userIndex);</span><br><span class="line">                        <span class="keyword">this</span>.userBiases.plus(userIndex, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error - <span class="keyword">this</span>.regBias * factor));</span><br><span class="line">                        <span class="keyword">this</span>.loss += <span class="keyword">this</span>.regBias * factor * factor;</span><br><span class="line">                        <span class="keyword">double</span> itemBias = <span class="keyword">this</span>.itemBiases.get(itemIndex);</span><br><span class="line">                        <span class="keyword">this</span>.itemBiases.plus(itemIndex, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error - <span class="keyword">this</span>.regBias * itemBias));</span><br><span class="line">                        <span class="keyword">this</span>.loss += <span class="keyword">this</span>.regBias * itemBias * itemBias;</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">for</span>(<span class="keyword">int</span> factorIndex = <span class="number">0</span>; factorIndex &lt; <span class="keyword">this</span>.numFactors; ++factorIndex) &#123;</span><br><span class="line">                            <span class="keyword">double</span> userFactor = <span class="keyword">this</span>.userFactors.get(userIndex, factorIndex);</span><br><span class="line">                            <span class="keyword">double</span> itemFactor = <span class="keyword">this</span>.itemFactors.get(itemIndex, factorIndex);</span><br><span class="line">                            <span class="keyword">this</span>.userFactors.plus(userIndex, factorIndex, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error * itemFactor - (<span class="keyword">double</span>)<span class="keyword">this</span>.regUser * userFactor));</span><br><span class="line">                            <span class="keyword">this</span>.itemFactors.plus(itemIndex, factorIndex, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error * (userFactor + <span class="keyword">this</span>.factorVector.get(factorIndex)) - (<span class="keyword">double</span>)<span class="keyword">this</span>.regItem * itemFactor));</span><br><span class="line">                            <span class="keyword">this</span>.loss += (<span class="keyword">double</span>)<span class="keyword">this</span>.regUser * userFactor * userFactor + (<span class="keyword">double</span>)<span class="keyword">this</span>.regItem * itemFactor * itemFactor;</span><br><span class="line">                            steps[factorIndex] += error * itemFactor * scale;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">int</span> size = userVector.getNumEntries();</span><br><span class="line">                    Iterator var23 = userVector.iterator();</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">while</span>(var23.hasNext()) &#123;</span><br><span class="line">                        VectorEntry vectorEntry = (VectorEntry)var23.next();</span><br><span class="line">                        <span class="keyword">int</span> index = vectorEntry.index();</span><br><span class="line"></span><br><span class="line">                        <span class="keyword">for</span>(<span class="keyword">int</span> factorIndex = <span class="number">0</span>; factorIndex &lt; <span class="keyword">this</span>.numFactors; ++factorIndex) &#123;</span><br><span class="line">                            factor = <span class="keyword">this</span>.impItemFactors.get(index, factorIndex);</span><br><span class="line">                            <span class="keyword">this</span>.impItemFactors.plus(index, factorIndex, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (steps[factorIndex] - <span class="keyword">this</span>.regImpItem * factor * (<span class="keyword">double</span>)size));</span><br><span class="line">                            <span class="keyword">this</span>.loss += <span class="keyword">this</span>.regImpItem * factor * factor * (<span class="keyword">double</span>)size;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">this</span>.loss *= <span class="number">0.5D</span>;</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.isConverged(iterationStep) &amp;&amp; <span class="keyword">this</span>.earlyStop) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">this</span>.updateLRate(iterationStep);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">double</span> <span class="title">predict</span><span class="params">(<span class="keyword">int</span> userIndex, <span class="keyword">int</span> itemIndex, DenseVector factorVector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">double</span> value = <span class="keyword">this</span>.userBiases.get(userIndex) + <span class="keyword">this</span>.itemBiases.get(itemIndex) + <span class="keyword">this</span>.globalMean;</span><br><span class="line">        DenseVector userFactorVector = <span class="keyword">this</span>.userFactors.row(userIndex);</span><br><span class="line">        DenseVector itemFactorVector = <span class="keyword">this</span>.itemFactors.row(itemIndex);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> index = <span class="number">0</span>; index &lt; <span class="keyword">this</span>.numFactors; ++index) &#123;</span><br><span class="line">            value += (factorVector.get(index) + userFactorVector.get(index)) * itemFactorVector.get(index);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">double</span> <span class="title">predict</span><span class="params">(<span class="keyword">int</span> userIndex, <span class="keyword">int</span> itemIndex)</span> </span>&#123;</span><br><span class="line">        SequentialSparseVector userVector = <span class="keyword">this</span>.trainMatrix.row(userIndex);</span><br><span class="line">        <span class="keyword">this</span>.factorVector.assign((index, value) -&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.0D</span>;</span><br><span class="line">        &#125;);</span><br><span class="line">        Iterator var4 = userVector.iterator();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(var4.hasNext()) &#123;</span><br><span class="line">            VectorEntry vectorEntry = (VectorEntry)var4.next();</span><br><span class="line">            <span class="keyword">this</span>.factorVector.assign((index, value) -&gt; &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">this</span>.impItemFactors.row(vectorEntry.index()).get(index) + value;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">double</span> scale = Math.sqrt((<span class="keyword">double</span>)userVector.getNumEntries());</span><br><span class="line">        <span class="keyword">if</span> (scale &gt; <span class="number">0.0D</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.factorVector.assign((index, value) -&gt; &#123;</span><br><span class="line">                <span class="keyword">return</span> value / scale;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.predict(userIndex, itemIndex, <span class="keyword">this</span>.factorVector);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="预测公式">预测公式</h1>
<p><span class="math inline">\(\hat{r}_{u i}=\mu+b_{i}+b_{u}+q_{i}^{T}\left(p_{u}+|N(u)|^{-\frac{1}{2}} \sum_{j \in N(u)} y_{j}\right)\)</span></p>
<p>首先我们需要明确预测公式各部分的含义：</p>
<ul>
<li><p><span class="math inline">\(\mu\)</span>：训练集中所有评分的均值，表示训练数据的总体评分情况，对于固定的数据集是一个常数，在代码中使用<code>this.globalMean</code>表示。</p></li>
<li><p><span class="math inline">\(b_{u}\)</span>：用户偏置，独立于物品特征的因素，表示某一特定用户的打分习惯，例如，对于批判型用户倾向于打低分，乐观型用户倾向于打高分，在代码中使用<code>this.userBiases.get(userIndex)</code>表示，需要注意的是，特定用户的用户偏置需要使用用户ID来进行索引。</p></li>
<li><p><span class="math inline">\(b_{i}\)</span>：物品偏置，独立于用户兴趣的因素，表示某一特定物品得到的打分情况，例如，好的电影获得的总体评分偏高，而坏的电影获得的评分偏低，在代码中使用<code>this.itemBiases.get(itemIndex)</code>表示，需要注意的是，特定物品的物品偏置需要使用物品ID来进行索引。</p></li>
<li><p><span class="math inline">\(q_{i}\)</span>：物品隐向量，对用户物品评分矩阵分解后得到，在代码中使用<code>itemFactorVector.get(index)</code>表示，同样地，需要使用<code>index</code>来进行索引。</p></li>
<li><p><span class="math inline">\(p_{u}\)</span>：用户隐向量，对用户物品评分矩阵分解后得到，在代码中使用<code>userFactorVector.get(index)</code>表示，同样地，需要使用<code>index</code>来进行索引。</p></li>
<li><p><span class="math inline">\(|N(u)|\)</span>：用户<span class="math inline">\(u\)</span>在评分过的历史物品的数量，即在隐式反馈特征中有行为的个数。</p></li>
<li><p><span class="math inline">\(y_{j}\)</span>：用户<span class="math inline">\(u\)</span>对于交互过的物品<span class="math inline">\(j\)</span>的个人喜好偏置，在代码中，<span class="math inline">\(|N(u)|^{-\frac{1}{2}} \sum_{j \in N(u)} y_{j}\)</span>整体使用<code>factorVector.get(index)</code>表示。</p></li>
</ul>
<p>SVD++中加入了隐式反馈信息，除了假设评分矩阵中的物品有一个隐因子向量外，用户有过交互行为的物品集合也都有一个隐因子向量，维度相同，将用户操作过的物品隐因子向量加起来可以用来表示用户的兴趣爱好。</p>
<p>以下我们可以来看一下预测函数的代码，首先展示<span class="math inline">\(\sum_{j \in N(u)} y_{j}\)</span>这一部分：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">SequentialSparseVector userVector = <span class="keyword">this</span>.trainMatrix.row(userIndex);</span><br><span class="line"><span class="keyword">this</span>.factorVector.assign((index, value) -&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.0D</span>;</span><br><span class="line">&#125;);</span><br><span class="line">Iterator var4 = userVector.iterator();</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(var4.hasNext()) &#123;</span><br><span class="line">    VectorEntry vectorEntry = (VectorEntry)var4.next();</span><br><span class="line">    <span class="keyword">this</span>.factorVector.assign((index, value) -&gt; &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.impItemFactors.row(vectorEntry.index()).get(index) + value;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这块的代码非常的简洁，但不是很好理解，这个Lambda表达式一上来就有一种云里雾里的感觉，我们首先需要明确Lambda表达式的作用，有一个例子可以帮助我们理解，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">(x, y) -&gt; x - y;</span><br></pre></td></tr></table></figure>
<p>在以上的匿名方法中，接收了<code>x</code>和<code>y</code>两个参数，并返回它们的差值。与以上案例不同的是，程序中的Lambda表达式重写了接口类的方法，我们可以首先来观察一下接口类<code>VectorAssigner</code>中被重写的<code>getValue()</code>方法，代码如下所示，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">VectorAssigner</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">double</span> <span class="title">getValue</span><span class="params">(<span class="keyword">int</span> var1, <span class="keyword">double</span> var2)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，接口类的方法传入两个参数，一个是<code>int</code>类型，另外一个是<code>double</code>类型，这和Lambda表达式中传入的<code>index</code>和<code>value</code>正好对应。明确了以上之后，我们还需要搞清楚<code>assign()</code>方法的使用，在<code>DenseVector</code>中<code>assign()</code>方法如下所示，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DenseVector <span class="title">assign</span><span class="params">(VectorAssigner vectorAssigner)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> index = <span class="number">0</span>; index &lt; <span class="keyword">this</span>.cardinality(); ++index) &#123;</span><br><span class="line">        <span class="keyword">this</span>.set(index, vectorAssigner.getValue(index, <span class="keyword">this</span>.get(index)));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>assign()</code>方法中循环调用了<code>set()</code>方法对<code>factorVector</code>进行赋值，在初始的时候对其进行全0赋值，因为重写的<code>getValue()</code>方法<code>return 0</code>，如下图所示。</p>
<p><img title src="file:///C:/Users/Rainy_Universe/AppData/Roaming/marktext/images/2022-03-23-21-03-50-image.png" alt width="446" data-align="center"></p>
<p>再来看以下一部分代码对<span class="math inline">\(\sum_{j \in N(u)} y_{j}\)</span>进行计算，代码如下所示，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(var4.hasNext()) &#123;</span><br><span class="line">    VectorEntry vectorEntry = (VectorEntry)var4.next();</span><br><span class="line">    <span class="keyword">this</span>.factorVector.assign((index, value) -&gt; &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.impItemFactors.row(vectorEntry.index()).get(index) + value;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先我们需要明确迭代器是<code>userVector</code>的迭代器，也就是对用户交互过的每一个物品进行遍历，每一次调用<code>assign()</code>方法都遍历所有的<code>index</code>，这里的<code>index</code>可以理解为隐因子向量的维度索引，每一个用户交互过的物品都对应一个隐因子向量，迭代器将所有用户交互过的物品的隐因子向量进行相加，求得<span class="math inline">\(\sum_{j \in N(u)} y_{j}\)</span>。</p>
<p>与公式进行比对，我们发现还缺少一部分<span class="math inline">\(|N(u)|^{-\frac{1}{2}}\)</span>，公式的这一部分是为了消除不同<span class="math inline">\(|N(u)|\)</span>个数引起的差异，如果使用<span class="math inline">\(|N(u)|\)</span>，则用户交互过的物品个数也会对最后的效果产生影响，而这显然是不利的，我们再来看这一部分的代码实现，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> scale = Math.sqrt((<span class="keyword">double</span>)userVector.getNumEntries());</span><br><span class="line">    <span class="keyword">if</span> (scale &gt; <span class="number">0.0D</span>) &#123;</span><br><span class="line">        <span class="keyword">this</span>.factorVector.assign((index, value) -&gt; &#123;</span><br><span class="line">            <span class="keyword">return</span> value / scale;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以直接通过调用<code>userVector.getNumEntries()</code>方法来获得当前用户交互过的物品数量，开平方后得到缩放比例，再将隐因子向量的和除以缩放比例最终得到<span class="math inline">\(|N(u)|^{-\frac{1}{2}} \sum_{j \in N(u)} y_{j}\)</span>这一部分的值。</p>
<p>预测函数到这里并没有结束，程序中将预测函数的上一部分进行讲解的代码进行了封装，然后在总的预测函数中进行调用，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">double</span> <span class="title">predict</span><span class="params">(<span class="keyword">int</span> userIndex, <span class="keyword">int</span> itemIndex, DenseVector factorVector)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> value = <span class="keyword">this</span>.userBiases.get(userIndex) + <span class="keyword">this</span>.itemBiases.get(itemIndex) + <span class="keyword">this</span>.globalMean;</span><br><span class="line">    DenseVector userFactorVector = <span class="keyword">this</span>.userFactors.row(userIndex);</span><br><span class="line">    DenseVector itemFactorVector = <span class="keyword">this</span>.itemFactors.row(itemIndex);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> index = <span class="number">0</span>; index &lt; <span class="keyword">this</span>.numFactors; ++index) &#123;</span><br><span class="line">        value += (factorVector.get(index) + userFactorVector.get(index)) * itemFactorVector.get(index);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>value</code>在初始化时就被赋上<span class="math inline">\(\mu+b_{i}+b_{u}\)</span>的值，在这里主要是关注<code>index</code>的循环，<code>index</code>在这里指的是隐因子向量的维度索引，<code>factorVector</code>表示当前用户交互过的物品隐因子偏置向量，能够表现出用户对于交互过的一些物品的隐因子的倾向，<code>userFactorVector</code>表示用户隐因子向量，<code>itemFactorVector</code>表示物品隐因子向量，这些隐因子向量的维度是相同的，所以可以进行相同的循环操作，最后返回的值即预测值，至此预测函数的部分就结束了。</p>
<h1 id="损失函数公式">损失函数公式</h1>
<p><span class="math inline">\(\begin{aligned} \min _{b_{i}, b_{w}, q_{i}, p_{u}} &amp;\sum_{(u, i) \in K}\left(r_{u i}-\mu-b_{u}-b_{i}-q_{i}^{T}\left(p_{u}+|N(u)|^{-\frac{1}{2}} \sum_{j \in N(u)} y_{j}\right)\right)^{2} \\&amp;+\lambda\left\{\sum _ { u } \left(b_{u}^{2}\right.\right. \left.\left.+\left\|p_{u}\right\|^{2}\right)+\sum_{i}\left(b_{i}^{2}+\left\|q_{i}\right\|^{2}+\left\|y_{i}\right\|^{2}\right)\right\} \end{aligned}\)</span></p>
<p>我们首先来计算<span class="math inline">\(\sum_{(u, i) \in K}\left(r_{u i}-\mu-b_{u}-b_{i}-q_{i}^{T}\left(p_{u}+|N(u)|^{-\frac{1}{2}} \sum_{j \in N(u)} y_{j}\right)\right)^{2}\)</span>这一部分的值，虽然看起来繁杂，但可以简化为<span class="math inline">\((r_{ui}-\hat{r}_{ui})^2\)</span>，代码如下所示，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">VectorEntry vectorEntry = (VectorEntry)var7.next();</span><br><span class="line"><span class="keyword">double</span> error = vectorEntry.get() - <span class="keyword">this</span>.predict(userIndex, itemIndex, <span class="keyword">this</span>.factorVector);</span><br><span class="line"><span class="keyword">this</span>.loss += error * error;</span><br></pre></td></tr></table></figure>
<p>通过<code>vectorEntry.get()</code>方法可以获得实际的真实评分值，调用<code>predict()</code>方法可以获得预测评分值，二者相减得到误差，再进行平方即可求得这一部分的值。需要注意的是，在调用<code>predict()</code>方法时需要首先计算用户交互过物品的隐因子向量<code>factorVector</code>，求法与<code>predict()</code>方法中的求法相同，代码如下所示，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">this</span>.factorVector.assign((indexx, value) -&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.0D</span>;</span><br><span class="line">&#125;);</span><br><span class="line">Iterator var5 = userVector.iterator();</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(var5.hasNext()) &#123;</span><br><span class="line">    VectorEntry vectorEntry = (VectorEntry)var5.next();</span><br><span class="line">    <span class="keyword">this</span>.factorVector.assign((indexx, value) -&gt; &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.impItemFactors.row(vectorEntry.index()).get(indexx) + value;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">double</span> scale = Math.pow((<span class="keyword">double</span>)userVector.getNumEntries(), -<span class="number">0.5D</span>);</span><br><span class="line"><span class="keyword">this</span>.factorVector.assign((indexx, value) -&gt; &#123;</span><br><span class="line">    <span class="keyword">return</span> value * scale;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>再接下来我们对公式的<span class="math inline">\(\lambda({\sum _ { u } b_{u}^{2} + \sum _ { i } b_{i}^{2}})\)</span>进行求解，代码如下所示，其中<code>factor</code>指的是用户<code>u</code>的用户偏置，<code>itemBias</code>指的是物品<code>i</code>的物品偏置。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">factor = <span class="keyword">this</span>.userBiases.get(userIndex);</span><br><span class="line"><span class="keyword">this</span>.loss += <span class="keyword">this</span>.regBias * factor * factor;</span><br><span class="line"><span class="keyword">double</span> itemBias = <span class="keyword">this</span>.itemBiases.get(itemIndex);</span><br><span class="line"><span class="keyword">this</span>.loss += <span class="keyword">this</span>.regBias * itemBias * itemBias;</span><br></pre></td></tr></table></figure>
<p>然后我们对公式的<span class="math inline">\(\lambda({\sum _ { u } ||p_{u}||^{2} + \sum _ { i } ||q_{i}||^{2}})\)</span>进行求解，首先进入隐因子向量维度索引的循环，根据特定用户的用户索引<code>userIndex</code>和隐因子向量维度索引<code>factorIndex</code>得到用户隐因子值<code>userFactor</code>，根据特定物品的物品索引<code>itemIndex</code>和隐因子向量维度索引<code>factorIndex</code>得到物品隐因子值<code>itemFactor</code>，代码如下所示，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> factorIndex = <span class="number">0</span>; factorIndex &lt; <span class="keyword">this</span>.numFactors; ++factorIndex) &#123;</span><br><span class="line">    <span class="keyword">double</span> userFactor = <span class="keyword">this</span>.userFactors.get(userIndex, factorIndex);</span><br><span class="line">    <span class="keyword">double</span> itemFactor = <span class="keyword">this</span>.itemFactors.get(itemIndex, factorIndex);</span><br><span class="line">    <span class="keyword">this</span>.loss += (<span class="keyword">double</span>)<span class="keyword">this</span>.regUser * userFactor * userFactor + (<span class="keyword">double</span>)<span class="keyword">this</span>.regItem * itemFactor * itemFactor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后我们对公式的<span class="math inline">\(\lambda \sum _ i ||y_{i}||^2\)</span>进行求解，这里可以借鉴预测函数中<span class="math inline">\(y_{i}\)</span>的求和，不过损失函数中是对其先平方之后再进行求和，代码如下，</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(var23.hasNext()) &#123;</span><br><span class="line">    VectorEntry vectorEntry = (VectorEntry)var23.next();</span><br><span class="line">    <span class="keyword">int</span> index = vectorEntry.index();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> factorIndex = <span class="number">0</span>; factorIndex &lt; <span class="keyword">this</span>.numFactors; ++factorIndex) &#123;</span><br><span class="line">        factor = <span class="keyword">this</span>.impItemFactors.get(index, factorIndex);</span><br><span class="line">        <span class="keyword">this</span>.loss += <span class="keyword">this</span>.regImpItem * factor * factor * (<span class="keyword">double</span>)size;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="更新公式">更新公式</h1>
<p>最后我们关注一下更新函数的部分：</p>
<p><span class="math inline">\(\begin{array}{c} e_{u i}=r_{u i}-\hat{r}_{u i} \\ b_{u} \leftarrow b_{u}+\gamma \cdot\left(e_{u i}-\lambda \cdot b_{u}\right) \\ b_{i} \leftarrow b_{i}+\gamma \cdot\left(e_{u i}-\lambda \cdot b_{i}\right) \\ p_{u} \leftarrow p_{u}+\gamma \cdot\left(e_{u i} \cdot q_{i}-\lambda \cdot p_{u}\right) \\ q_{i} \leftarrow q_{i}+\gamma \cdot\left(e_{u i} \cdot\left(p_{u}+\frac{1}{\sqrt{\left\|R_{u}\right\|}} \sum_{j \in R_{u}} y_{j}\right)-\lambda \cdot q_{i}\right) \\ y_{j} \leftarrow y_{j}+\gamma \cdot\left(e_{u i} \cdot \frac{1}{\sqrt{\left\|R_{u}\right\|}} \cdot q_{i}-\lambda \cdot q_{u}\right) \end{array}\)</span></p>
<ul>
<li><span class="math inline">\(b_{u}\)</span>的更新：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">this</span>.userBiases.plus(userIndex, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error - <span class="keyword">this</span>.regBias * factor));</span><br></pre></td></tr></table></figure>
<ul>
<li><span class="math inline">\(b_{i}\)</span>的更新：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">this</span>.itemBiases.plus(itemIndex, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error - <span class="keyword">this</span>.regBias * itemBias));</span><br></pre></td></tr></table></figure>
<ul>
<li><span class="math inline">\(p_{u}\)</span>和<span class="math inline">\(q_{i}\)</span>的更新：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> factorIndex = <span class="number">0</span>; factorIndex &lt; <span class="keyword">this</span>.numFactors; ++factorIndex) &#123;</span><br><span class="line">    <span class="keyword">double</span> userFactor = <span class="keyword">this</span>.userFactors.get(userIndex, factorIndex);</span><br><span class="line">    <span class="keyword">double</span> itemFactor = <span class="keyword">this</span>.itemFactors.get(itemIndex, factorIndex);</span><br><span class="line">    <span class="keyword">this</span>.userFactors.plus(userIndex, factorIndex, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error * itemFactor - (<span class="keyword">double</span>)<span class="keyword">this</span>.regUser * userFactor));</span><br><span class="line">    <span class="keyword">this</span>.itemFactors.plus(itemIndex, factorIndex, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (error * (userFactor + <span class="keyword">this</span>.factorVector.get(factorIndex)) - (<span class="keyword">double</span>)<span class="keyword">this</span>.regItem * itemFactor));</span><br><span class="line">    steps[factorIndex] += error * itemFactor * scale;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>需要注意的是，这里记录了<code>step</code>数组，其中记录的是<span class="math inline">\(e_{u i} \cdot \frac{1}{\sqrt{\left|R_{u}\right|}} \cdot q_{i}\)</span>的值（为了<span class="math inline">\(y_{j}\)</span>的更新）。</p>
<ul>
<li><span class="math inline">\(y_{j}\)</span>的更新：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Iterator var23 = userVector.iterator();</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(var23.hasNext()) &#123;</span><br><span class="line">    VectorEntry vectorEntry = (VectorEntry)var23.next();</span><br><span class="line">    <span class="keyword">int</span> index = vectorEntry.index();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> factorIndex = <span class="number">0</span>; factorIndex &lt; <span class="keyword">this</span>.numFactors; ++factorIndex) &#123;</span><br><span class="line">        factor = <span class="keyword">this</span>.impItemFactors.get(index, factorIndex);</span><br><span class="line">        <span class="keyword">this</span>.impItemFactors.plus(index, factorIndex, (<span class="keyword">double</span>)<span class="keyword">this</span>.learnRate * (steps[factorIndex] - <span class="keyword">this</span>.regImpItem * factor * (<span class="keyword">double</span>)size));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里需要区分一下，<code>index</code>指的是用户的索引，<code>factorIndex</code>指的是隐因子向量的索引，<code>factor</code>指的是与当前用户交互过的物品隐因子值（已知隐因子向量索引<code>factorIndex</code>）。</p>
]]></content>
      <categories>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
      </tags>
  </entry>
</search>
